[
    {
        "chunk_id": "ff36e54d-99f5-4d1c-ba4b-dbfe43be3156",
        "text": "## **Inference Cloud powered by Qualcomm **  **Efficient and Scalable AI - No Complex Infrastructure Management Required**  Experience seamless one-click AI deployment. Effortlessly use generative AI models to build custom applications and agents using popular frameworks.  Inference Cloud powered by Qualcomm and leveraging the Qualcomm Cloud AI 100 Ultra.  **Ease AI Deployments** The web-based platform for deployment, configuration, and monitoring simplifies access to leading AI models as well",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 2,
            "chunk_id": "ff36e54d-99f5-4d1c-ba4b-dbfe43be3156",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Inference Cloud powered by Qualcomm **  **Efficient and Scalable AI - No Complex Infrastructure Management Required**  Experience seamless one-click AI deployment. Effortlessly use generative AI models to build custom applications and agents using popular frameworks.  Inference Cloud powered by Qualcomm and leveraging the Qualcomm Cloud AI 100 Ultra.  **Ease AI Deployments** The web-based platform for deployment, configuration, and monitoring simplifies access to leading AI models as well"
        }
    },
    {
        "chunk_id": "d45c2736-4373-483a-b72b-62cf86cab26b",
        "text": "simplifies access to leading AI models as well as pre-built applications and agents. API endpoints enable rapid integration with your existing applications and workflows. You pay only for what you use, with pricing based on tokens that vary for selected AI models.  **Run with Confidence**  Enjoy high availability and strict data privacy with no storage of model inputs or outputs. Our solution is designed and stress-tested for enterprise environments.  **Top Performance, Future-Proofed**",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 2,
            "chunk_id": "d45c2736-4373-483a-b72b-62cf86cab26b",
            "embedding_model": "text-embedding-3-large",
            "text": "simplifies access to leading AI models as well as pre-built applications and agents. API endpoints enable rapid integration with your existing applications and workflows. You pay only for what you use, with pricing based on tokens that vary for selected AI models.  **Run with Confidence**  Enjoy high availability and strict data privacy with no storage of model inputs or outputs. Our solution is designed and stress-tested for enterprise environments.  **Top Performance, Future-Proofed**"
        }
    },
    {
        "chunk_id": "6c4ed659-154c-4010-b9e4-b78a36ac6145",
        "text": "**Top Performance, Future-Proofed** Maximize performance and cost efficiency with Qualcomm Cloud AI 100 Ultra inference accelerators, embedded optimization techniques, and state-of-the-art models available in the  Qualcomm AI Inference Suite for Cloud.  **Customized Options Available** For specialized needs or enhanced scalability, Cirrascale offers the Qualcomm Cloud AI 100 Ultra in a bare-metal solution that enables deep integration of custom DevOps workforces with your inference",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 2,
            "chunk_id": "6c4ed659-154c-4010-b9e4-b78a36ac6145",
            "embedding_model": "text-embedding-3-large",
            "text": "**Top Performance, Future-Proofed** Maximize performance and cost efficiency with Qualcomm Cloud AI 100 Ultra inference accelerators, embedded optimization techniques, and state-of-the-art models available in the  Qualcomm AI Inference Suite for Cloud.  **Customized Options Available** For specialized needs or enhanced scalability, Cirrascale offers the Qualcomm Cloud AI 100 Ultra in a bare-metal solution that enables deep integration of custom DevOps workforces with your inference"
        }
    },
    {
        "chunk_id": "f0cebfb1-7523-42a2-949f-ec26baaed15b",
        "text": "of custom DevOps workforces with your inference requirements. We work with you to develop the solution you need.  **Inference Cloud Powered by Qualcomm**  **The Qualcomm AI Inference Suite with the Qualcomm Cloud AI 100 Ultra**      - ​ Play with generative AI applications with easy-to-use endpoints.      - ​ Build your applications with Qualcomm Cloud AI tutorials and documentation.      - ​ Start with free access to test, then seamlessly transition to production using the Inference Cloud",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 2,
            "chunk_id": "f0cebfb1-7523-42a2-949f-ec26baaed15b",
            "embedding_model": "text-embedding-3-large",
            "text": "of custom DevOps workforces with your inference requirements. We work with you to develop the solution you need.  **Inference Cloud Powered by Qualcomm**  **The Qualcomm AI Inference Suite with the Qualcomm Cloud AI 100 Ultra**      - ​ Play with generative AI applications with easy-to-use endpoints.      - ​ Build your applications with Qualcomm Cloud AI tutorials and documentation.      - ​ Start with free access to test, then seamlessly transition to production using the Inference Cloud"
        }
    },
    {
        "chunk_id": "7f049747-5b6b-4e59-8099-60d9526b8c85",
        "text": "to production using the Inference Cloud powered by Qualcomm.  **Ready-To-Use Applications and Agents**    - ​ Chatbot ​    - ​ Summarization ​   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 2,
            "chunk_id": "7f049747-5b6b-4e59-8099-60d9526b8c85",
            "embedding_model": "text-embedding-3-large",
            "text": "to production using the Inference Cloud powered by Qualcomm.  **Ready-To-Use Applications and Agents**    - ​ Chatbot ​    - ​ Summarization ​   -----"
        }
    },
    {
        "chunk_id": "8192970e-9ec5-4de8-9df0-6b5fa6ae61ff",
        "text": "- ​ AI agents ​  - ​ Image generation ​  - ​ Retrieval-augmented text generation (RAG) ​  - ​ Real-time translation ​  - ​ Code development ​  - ​ Real-time transcription ​  - ​ Your next use case   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 3,
            "chunk_id": "8192970e-9ec5-4de8-9df0-6b5fa6ae61ff",
            "embedding_model": "text-embedding-3-large",
            "text": "- ​ AI agents ​  - ​ Image generation ​  - ​ Retrieval-augmented text generation (RAG) ​  - ​ Real-time translation ​  - ​ Code development ​  - ​ Real-time transcription ​  - ​ Your next use case   -----"
        }
    },
    {
        "chunk_id": "7081a593-4f03-4ff4-9dff-f5bfea62d35b",
        "text": "## **We Help NVIDIA® Inception Members **  Cirrascale Cloud Services helps NVIDIA Inception members get the most out of their program benefits. Whether you're a community member or a premier member, we can help you.  **What is the NVIDIA Inception Program?** NVIDIA Inception is designed to help startups build their products and grow faster. Members get exclusive technology discounts, free technical training, marketing opportunities, and increased exposure to the venture capital community. The",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 5,
            "chunk_id": "7081a593-4f03-4ff4-9dff-f5bfea62d35b",
            "embedding_model": "text-embedding-3-large",
            "text": "## **We Help NVIDIA® Inception Members **  Cirrascale Cloud Services helps NVIDIA Inception members get the most out of their program benefits. Whether you're a community member or a premier member, we can help you.  **What is the NVIDIA Inception Program?** NVIDIA Inception is designed to help startups build their products and grow faster. Members get exclusive technology discounts, free technical training, marketing opportunities, and increased exposure to the venture capital community. The"
        }
    },
    {
        "chunk_id": "fc287f31-d720-4c2a-a207-93fc8fe569fc",
        "text": "exposure to the venture capital community. The program is free and available for tech startups of all stages  NVIDIA works closely with members to provide the best technical tools, latest resources, and opportunities to connect with investors. As your startup matures, your program benefits also evolve to further your growth. Premier members receive increased NVIDIA marketing support, access to Premier-only member events, and a dedicated NVIDIA relationship manager.  **What Can Cirrascale Do To",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 5,
            "chunk_id": "fc287f31-d720-4c2a-a207-93fc8fe569fc",
            "embedding_model": "text-embedding-3-large",
            "text": "exposure to the venture capital community. The program is free and available for tech startups of all stages  NVIDIA works closely with members to provide the best technical tools, latest resources, and opportunities to connect with investors. As your startup matures, your program benefits also evolve to further your growth. Premier members receive increased NVIDIA marketing support, access to Premier-only member events, and a dedicated NVIDIA relationship manager.  **What Can Cirrascale Do To"
        }
    },
    {
        "chunk_id": "41a77f29-9a73-4a93-8417-b2baa0176ca6",
        "text": "manager.  **What Can Cirrascale Do To Help?** Cirrascale has been helping NVIDIA Inception program members such as AssemblyAI, MosaicML, Metaphor, and more, evolve faster by providing them with unique benefits. By partnering with Cirrascale, approved Inception members can purchase hardware at preferred pricing levels, receive discounts on cloud and managed services provided by Cirrascale, and partner with us to receive referral discounts for other startups you refer.  Cirrascale Cloud Services",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 5,
            "chunk_id": "41a77f29-9a73-4a93-8417-b2baa0176ca6",
            "embedding_model": "text-embedding-3-large",
            "text": "manager.  **What Can Cirrascale Do To Help?** Cirrascale has been helping NVIDIA Inception program members such as AssemblyAI, MosaicML, Metaphor, and more, evolve faster by providing them with unique benefits. By partnering with Cirrascale, approved Inception members can purchase hardware at preferred pricing levels, receive discounts on cloud and managed services provided by Cirrascale, and partner with us to receive referral discounts for other startups you refer.  Cirrascale Cloud Services"
        }
    },
    {
        "chunk_id": "3f542214-97c1-40ae-87b2-abea3a10f140",
        "text": "startups you refer.  Cirrascale Cloud Services works closely with NVIDIA and your assigned dedicated relationship manager to provide you with the best experience as an Inception member.  **NVIDIA® Inception Benefits with Cirrascale**  **Full Cloud Services**  We offer fully-managed GPU clusters at a fraction of the cost of traditional cloud service providers. These bare-metal servers are completely dedicated to you with no contention and no performance issues due to virtualization overhead.",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 5,
            "chunk_id": "3f542214-97c1-40ae-87b2-abea3a10f140",
            "embedding_model": "text-embedding-3-large",
            "text": "startups you refer.  Cirrascale Cloud Services works closely with NVIDIA and your assigned dedicated relationship manager to provide you with the best experience as an Inception member.  **NVIDIA® Inception Benefits with Cirrascale**  **Full Cloud Services**  We offer fully-managed GPU clusters at a fraction of the cost of traditional cloud service providers. These bare-metal servers are completely dedicated to you with no contention and no performance issues due to virtualization overhead."
        }
    },
    {
        "chunk_id": "ca734c05-c5e8-4f81-9ed3-9e8b80517d48",
        "text": "issues due to virtualization overhead.  Our flat-rate, no surprises billing model means we can provide you with a price that is up to 30% lower than the other cloud service providers. We also don't nickel-and-dime you by charging to get your data into or out of our cloud. Instead, we charge no ingress or egress fees so you never receive a supplemental bill.  **Hardware Rebates**  We're one of NVIDIA's earliest NPN CSP Elite Compute partner's which allows us to sell hardware to you while",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 5,
            "chunk_id": "ca734c05-c5e8-4f81-9ed3-9e8b80517d48",
            "embedding_model": "text-embedding-3-large",
            "text": "issues due to virtualization overhead.  Our flat-rate, no surprises billing model means we can provide you with a price that is up to 30% lower than the other cloud service providers. We also don't nickel-and-dime you by charging to get your data into or out of our cloud. Instead, we charge no ingress or egress fees so you never receive a supplemental bill.  **Hardware Rebates**  We're one of NVIDIA's earliest NPN CSP Elite Compute partner's which allows us to sell hardware to you while"
        }
    },
    {
        "chunk_id": "177e0f4f-b3ba-435e-8179-8deb4dce96f7",
        "text": "which allows us to sell hardware to you while providing you with the maximum program member benefits for NVIDIA GPU discounts on eligible accelerator cards.   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 5,
            "chunk_id": "177e0f4f-b3ba-435e-8179-8deb4dce96f7",
            "embedding_model": "text-embedding-3-large",
            "text": "which allows us to sell hardware to you while providing you with the maximum program member benefits for NVIDIA GPU discounts on eligible accelerator cards.   -----"
        }
    },
    {
        "chunk_id": "f671e364-3771-47f2-a145-a7a7b3e95889",
        "text": "These discounts are provided to you up-front and show on your invoice so that you receive the benefit immediately. We then work with NVIDIA to receive the rebates on the back end. We can work with you to ensure you get the absolute most out of your NVIDIA Inception membership.  **Managed Services** Our managed services offering is designed to give you the edge without worrying about server management or maintenance. You can focus on what matters: solving problems, speeding up your workflow and",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 6,
            "chunk_id": "f671e364-3771-47f2-a145-a7a7b3e95889",
            "embedding_model": "text-embedding-3-large",
            "text": "These discounts are provided to you up-front and show on your invoice so that you receive the benefit immediately. We then work with NVIDIA to receive the rebates on the back end. We can work with you to ensure you get the absolute most out of your NVIDIA Inception membership.  **Managed Services** Our managed services offering is designed to give you the edge without worrying about server management or maintenance. You can focus on what matters: solving problems, speeding up your workflow and"
        }
    },
    {
        "chunk_id": "9363d6a2-bf8c-441e-960a-92a3bc449036",
        "text": "solving problems, speeding up your workflow and taking advantage of cutting-edge computing power.  Once you purchase your hardware, Cirrascale can provide full managed services with specialized discounts so that you don't have to deal with long-term data center contracts or managing your hardware. We even include break/fix and RMA service to our customers. It's truly worry free with Zero DevOps.  **Referral Discounts**  Inception members are eligible to take part in our referral program",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 6,
            "chunk_id": "9363d6a2-bf8c-441e-960a-92a3bc449036",
            "embedding_model": "text-embedding-3-large",
            "text": "solving problems, speeding up your workflow and taking advantage of cutting-edge computing power.  Once you purchase your hardware, Cirrascale can provide full managed services with specialized discounts so that you don't have to deal with long-term data center contracts or managing your hardware. We even include break/fix and RMA service to our customers. It's truly worry free with Zero DevOps.  **Referral Discounts**  Inception members are eligible to take part in our referral program"
        }
    },
    {
        "chunk_id": "f1b0b1e5-6960-431e-8467-1c97fbb0dbbd",
        "text": "are eligible to take part in our referral program enabling them to save even more on their monthly service costs. Once part of our referral program, Inception members can refer other companies and receive discounts of up to 10% off their monthly service costs.  **Leasing Options** Cirrascale Cloud Services works with several financing companies to help provide leasing options for those Inception program members that need assistance with long-term solutions. We can work with your team to help",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 6,
            "chunk_id": "f1b0b1e5-6960-431e-8467-1c97fbb0dbbd",
            "embedding_model": "text-embedding-3-large",
            "text": "are eligible to take part in our referral program enabling them to save even more on their monthly service costs. Once part of our referral program, Inception members can refer other companies and receive discounts of up to 10% off their monthly service costs.  **Leasing Options** Cirrascale Cloud Services works with several financing companies to help provide leasing options for those Inception program members that need assistance with long-term solutions. We can work with your team to help"
        }
    },
    {
        "chunk_id": "38a174e0-4e7a-438e-89cc-45b29ccf90a0",
        "text": "solutions. We can work with your team to help manage the overall process, making it easy on you.  **Co-Marketing Opportunities** ​ If desired, we can help to provide additional marketing opportunities for Inception program members that work directly with Cirrascale. We promote your company within our own blog posts, social media postings, case studies, customer references, presentations and more.   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 6,
            "chunk_id": "38a174e0-4e7a-438e-89cc-45b29ccf90a0",
            "embedding_model": "text-embedding-3-large",
            "text": "solutions. We can work with your team to help manage the overall process, making it easy on you.  **Co-Marketing Opportunities** ​ If desired, we can help to provide additional marketing opportunities for Inception program members that work directly with Cirrascale. We promote your company within our own blog posts, social media postings, case studies, customer references, presentations and more.   -----"
        }
    },
    {
        "chunk_id": "53708007-fd17-48be-a6d7-e5a01f3596f1",
        "text": "## **Unleash Your Deep Learning Frameworks ** Whether you're just starting your GPU accelerated application development or ready to take your production and training applications to the next level, we provide you with the features you need in a cloud hosted environment that's unmatched. **Largest Variety of GPUs and Other Accelerators ** Other providers make you train your models on two generation old GPUs. Not us, we use the latest NVIDIA GPU accelerators, as well as other accelerator partner",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 8,
            "chunk_id": "53708007-fd17-48be-a6d7-e5a01f3596f1",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Unleash Your Deep Learning Frameworks ** Whether you're just starting your GPU accelerated application development or ready to take your production and training applications to the next level, we provide you with the features you need in a cloud hosted environment that's unmatched. **Largest Variety of GPUs and Other Accelerators ** Other providers make you train your models on two generation old GPUs. Not us, we use the latest NVIDIA GPU accelerators, as well as other accelerator partner"
        }
    },
    {
        "chunk_id": "c735f7ca-9c5a-40b8-8434-9d8ecfdcb968",
        "text": "as well as other accelerator partner architecture, to help you advance the AI revolution and enable HPC breakthroughs. Giving you accelerator options like these is what makes us different. **Physical, Dedicated GPUs and Servers ** We don’t virtualize GPUs and give you a sliver of the power, you get all of them and all of the resources that are included in our bare metal servers. No one shares these servers with you. Rest assured that when you use our service, you're getting a dedicated resource",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 8,
            "chunk_id": "c735f7ca-9c5a-40b8-8434-9d8ecfdcb968",
            "embedding_model": "text-embedding-3-large",
            "text": "as well as other accelerator partner architecture, to help you advance the AI revolution and enable HPC breakthroughs. Giving you accelerator options like these is what makes us different. **Physical, Dedicated GPUs and Servers ** We don’t virtualize GPUs and give you a sliver of the power, you get all of them and all of the resources that are included in our bare metal servers. No one shares these servers with you. Rest assured that when you use our service, you're getting a dedicated resource"
        }
    },
    {
        "chunk_id": "f4575bdc-ad2e-49d9-8ff9-8800a36abd75",
        "text": "our service, you're getting a dedicated resource for you, and you alone. **Perfect for AI Applications ** Building the ultimate generative AI, speech recognition or natural language processing application takes different tools along the way. Our variety of configuration offerings are set up to allow you to start small and scale up. **Real Transparent Pricing with No Surprises ** Others may claim to have transparent pricing, but once you start to look at the bottom line it can be a big surprise.",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 8,
            "chunk_id": "f4575bdc-ad2e-49d9-8ff9-8800a36abd75",
            "embedding_model": "text-embedding-3-large",
            "text": "our service, you're getting a dedicated resource for you, and you alone. **Perfect for AI Applications ** Building the ultimate generative AI, speech recognition or natural language processing application takes different tools along the way. Our variety of configuration offerings are set up to allow you to start small and scale up. **Real Transparent Pricing with No Surprises ** Others may claim to have transparent pricing, but once you start to look at the bottom line it can be a big surprise."
        }
    },
    {
        "chunk_id": "a39d63c8-a365-4fbe-9ab3-fbf9f24a5d41",
        "text": "look at the bottom line it can be a big surprise. From our start, we have always delivered a no surprises billing model with flat rates, so what you see as our price is what you'll pay. **Always the Latest Technology ** Our offerings are constantly being updated to offer our customers the highest level of service and technology available. Discover multi-GPU cloud servers with NVMe storage, the latest CPUs, and GPUs at the same price as what our competition offers older, more outdated",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 8,
            "chunk_id": "a39d63c8-a365-4fbe-9ab3-fbf9f24a5d41",
            "embedding_model": "text-embedding-3-large",
            "text": "look at the bottom line it can be a big surprise. From our start, we have always delivered a no surprises billing model with flat rates, so what you see as our price is what you'll pay. **Always the Latest Technology ** Our offerings are constantly being updated to offer our customers the highest level of service and technology available. Discover multi-GPU cloud servers with NVMe storage, the latest CPUs, and GPUs at the same price as what our competition offers older, more outdated"
        }
    },
    {
        "chunk_id": "fafbc374-1c4f-43fa-92b2-6af23c7ee27f",
        "text": "what our competition offers older, more outdated technology. Why pay more? **Need Something Different? Customize It ** Can't find a solution that meets your needs? Over the years, we've gotten a reputation for helping companies find the right solution that fits what they need. We work with start-ups and enterprise customers to build solutions that tackle today’s toughest challenges. We're always happy to discuss something special.   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 8,
            "chunk_id": "fafbc374-1c4f-43fa-92b2-6af23c7ee27f",
            "embedding_model": "text-embedding-3-large",
            "text": "what our competition offers older, more outdated technology. Why pay more? **Need Something Different? Customize It ** Can't find a solution that meets your needs? Over the years, we've gotten a reputation for helping companies find the right solution that fits what they need. We work with start-ups and enterprise customers to build solutions that tackle today’s toughest challenges. We're always happy to discuss something special.   -----"
        }
    },
    {
        "chunk_id": "b908dd0c-f82b-4963-b72c-88143cd5e4d0",
        "text": "## **Cloud Storage Solutions for Generative AI, Computer Vision, and NLP Workflows **  For unmatched performance in feeding your deep learning training models, you can't rely on the unknown storage performance that you're handed at the other cloud service providers. Instead, you can count on the Cirrascale Cloud Services platform to deliver a wide variety of storage options that will meet your needs.  **Local NVMe Storage** All of our systems support high-speed NVMe drives for your local",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 10,
            "chunk_id": "b908dd0c-f82b-4963-b72c-88143cd5e4d0",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Cloud Storage Solutions for Generative AI, Computer Vision, and NLP Workflows **  For unmatched performance in feeding your deep learning training models, you can't rely on the unknown storage performance that you're handed at the other cloud service providers. Instead, you can count on the Cirrascale Cloud Services platform to deliver a wide variety of storage options that will meet your needs.  **Local NVMe Storage** All of our systems support high-speed NVMe drives for your local"
        }
    },
    {
        "chunk_id": "bd0a8ddf-856e-4a7e-b66c-23532f87f5da",
        "text": "support high-speed NVMe drives for your local storage. By supporting NVMe drives in our cloud servers, customers gain the true advantages of state-of-the-art technology.  With reduced I/O overhead and various performance improvements in comparison to previous logical-device interfaces, including multiple, long command queues, and reduced latency, NVMe drives are superior for Generative AI, Autonomous Vehicle, Computer Vision, and Natural Language Processing (NLP) workflows.  Additionally, local",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 10,
            "chunk_id": "bd0a8ddf-856e-4a7e-b66c-23532f87f5da",
            "embedding_model": "text-embedding-3-large",
            "text": "support high-speed NVMe drives for your local storage. By supporting NVMe drives in our cloud servers, customers gain the true advantages of state-of-the-art technology.  With reduced I/O overhead and various performance improvements in comparison to previous logical-device interfaces, including multiple, long command queues, and reduced latency, NVMe drives are superior for Generative AI, Autonomous Vehicle, Computer Vision, and Natural Language Processing (NLP) workflows.  Additionally, local"
        }
    },
    {
        "chunk_id": "c26e1c88-657f-4fa5-8b34-f7df88610fb6",
        "text": "Processing (NLP) workflows.  Additionally, local bulk tier storage is also available to each server if customer need access to low-cost options.  **NVMe Hot-Tier Storage Solutions** Cirrascale uses NVMe flash-based solutions to deliver the overall best storage experience to its customers. Whether it's application workflows for generative AI, high-performance computing, medical imaging, financial risk simulations, or natural language processing, we have the right solutions to meet your needs.",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 10,
            "chunk_id": "c26e1c88-657f-4fa5-8b34-f7df88610fb6",
            "embedding_model": "text-embedding-3-large",
            "text": "Processing (NLP) workflows.  Additionally, local bulk tier storage is also available to each server if customer need access to low-cost options.  **NVMe Hot-Tier Storage Solutions** Cirrascale uses NVMe flash-based solutions to deliver the overall best storage experience to its customers. Whether it's application workflows for generative AI, high-performance computing, medical imaging, financial risk simulations, or natural language processing, we have the right solutions to meet your needs."
        }
    },
    {
        "chunk_id": "f17c3253-3923-4f4f-affa-865cfd18ed50",
        "text": "we have the right solutions to meet your needs.  Cirrascale has selected the WEKA Data Platform to utilize within its cloud for removing storage bottlenecks faced by customers who use inference and training datasets consisting of millions of files. Both data and metadata are distributed across the entire storage infrastructure to ensure massively parallel access to NVMe drives. The WEKA® Data Platform is certified as a high-performance data store solution for NVIDIA Cloud Partners like",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 10,
            "chunk_id": "f17c3253-3923-4f4f-affa-865cfd18ed50",
            "embedding_model": "text-embedding-3-large",
            "text": "we have the right solutions to meet your needs.  Cirrascale has selected the WEKA Data Platform to utilize within its cloud for removing storage bottlenecks faced by customers who use inference and training datasets consisting of millions of files. Both data and metadata are distributed across the entire storage infrastructure to ensure massively parallel access to NVMe drives. The WEKA® Data Platform is certified as a high-performance data store solution for NVIDIA Cloud Partners like"
        }
    },
    {
        "chunk_id": "4d6700c0-124b-4140-8ab0-4506e6aaf16f",
        "text": "store solution for NVIDIA Cloud Partners like Cirrascale and has demonstrated the ability to easily saturate any accelerator cluster and deliver ultra-fast performance per node across an NVIDIA Quantum InfiniBand network.  **Object Storage** Cost-effective, S3-compatible Object Storage that solves your biggest storage challenges while boosting interoperability, data durability, and operational efficiency making it possible to store practically limitless amounts of data, simply and cost",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 10,
            "chunk_id": "4d6700c0-124b-4140-8ab0-4506e6aaf16f",
            "embedding_model": "text-embedding-3-large",
            "text": "store solution for NVIDIA Cloud Partners like Cirrascale and has demonstrated the ability to easily saturate any accelerator cluster and deliver ultra-fast performance per node across an NVIDIA Quantum InfiniBand network.  **Object Storage** Cost-effective, S3-compatible Object Storage that solves your biggest storage challenges while boosting interoperability, data durability, and operational efficiency making it possible to store practically limitless amounts of data, simply and cost"
        }
    },
    {
        "chunk_id": "da2b2d0b-4921-4fbb-9138-75d98010b225",
        "text": "limitless amounts of data, simply and cost effectively.  Cirrascale offers object storage solutions that are perfect for the retention of massive amounts of unstructured data. Unlike other cloud solutions, Cirrascale provides the ability to store data in our cloud and not get hit with variable ingress/egress fees when trying to move data either from your office or from other cloud providers.   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 10,
            "chunk_id": "da2b2d0b-4921-4fbb-9138-75d98010b225",
            "embedding_model": "text-embedding-3-large",
            "text": "limitless amounts of data, simply and cost effectively.  Cirrascale offers object storage solutions that are perfect for the retention of massive amounts of unstructured data. Unlike other cloud solutions, Cirrascale provides the ability to store data in our cloud and not get hit with variable ingress/egress fees when trying to move data either from your office or from other cloud providers.   -----"
        }
    },
    {
        "chunk_id": "fc924d98-c5e6-4632-8c7a-65bebc7b719d",
        "text": "When part of a multi-tiered storage solution, and linked with a Cirrascale hot-tier storage offering, customers are able to seamlessly move data to be worked on between storage tiers. Overall, customers can reduce latency, improve throughput, and eliminate access charges.   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 11,
            "chunk_id": "fc924d98-c5e6-4632-8c7a-65bebc7b719d",
            "embedding_model": "text-embedding-3-large",
            "text": "When part of a multi-tiered storage solution, and linked with a Cirrascale hot-tier storage offering, customers are able to seamlessly move data to be worked on between storage tiers. Overall, customers can reduce latency, improve throughput, and eliminate access charges.   -----"
        }
    },
    {
        "chunk_id": "e8f30067-9bb0-4036-bb80-5cda9ca6c877",
        "text": "## **Flat, Stable Network Bandwidth ​**  Cirrascale utilizes the next-generation of networking for our high-performance, scalable, and  secure AI-driven data centers. Our cloud servers come standard with bonded ethernet network  connectivity to each physical node within our cloud. Unlike other providers, we provide the same network bandwidth speeds to our high-speed or object storage solutions too, so you don't experience any issues when accessing your data. For 90% of our customers, these",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 13,
            "chunk_id": "e8f30067-9bb0-4036-bb80-5cda9ca6c877",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Flat, Stable Network Bandwidth ​**  Cirrascale utilizes the next-generation of networking for our high-performance, scalable, and  secure AI-driven data centers. Our cloud servers come standard with bonded ethernet network  connectivity to each physical node within our cloud. Unlike other providers, we provide the same network bandwidth speeds to our high-speed or object storage solutions too, so you don't experience any issues when accessing your data. For 90% of our customers, these"
        }
    },
    {
        "chunk_id": "68424fe3-a3bf-49a0-8a27-0b85ac2c1e8d",
        "text": "your data. For 90% of our customers, these solutions work incredibly well for their AI heavy workflows; however, if higher bandwidth and decreased latency are needed, we have high-speed solutions to meet those needs. ## **Cirrascale Networking Benefits **  **Rail-Optimized NVIDIA Quantum InfiniBand Networking** Cirrascale Cloud Services provides its customers with the ability to go beyond and experience connectivity up to 3200Gb per server with NVIDIA Quantum InfiniBand networking.  Cirrascale",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 13,
            "chunk_id": "68424fe3-a3bf-49a0-8a27-0b85ac2c1e8d",
            "embedding_model": "text-embedding-3-large",
            "text": "your data. For 90% of our customers, these solutions work incredibly well for their AI heavy workflows; however, if higher bandwidth and decreased latency are needed, we have high-speed solutions to meet those needs. ## **Cirrascale Networking Benefits **  **Rail-Optimized NVIDIA Quantum InfiniBand Networking** Cirrascale Cloud Services provides its customers with the ability to go beyond and experience connectivity up to 3200Gb per server with NVIDIA Quantum InfiniBand networking.  Cirrascale"
        }
    },
    {
        "chunk_id": "2f9ba6fe-5c87-46a5-89fa-eba7e880fae9",
        "text": "NVIDIA Quantum InfiniBand networking.  Cirrascale utilizes rail-optimized NVIDIA Quantum InfiniBand networking that is designed to enhance AI workload performance by providing a high-bandwidth, low-latency interconnect that is particularly well-suited for dense, multi-node cloud server configurations. In this setup, the \"rail\" refers to optimized data pathways that connect servers within the same or adjacent racks, making the most of NVIDIA Quantum InfiniBand's ability to deliver exceptionally",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 13,
            "chunk_id": "2f9ba6fe-5c87-46a5-89fa-eba7e880fae9",
            "embedding_model": "text-embedding-3-large",
            "text": "NVIDIA Quantum InfiniBand networking.  Cirrascale utilizes rail-optimized NVIDIA Quantum InfiniBand networking that is designed to enhance AI workload performance by providing a high-bandwidth, low-latency interconnect that is particularly well-suited for dense, multi-node cloud server configurations. In this setup, the \"rail\" refers to optimized data pathways that connect servers within the same or adjacent racks, making the most of NVIDIA Quantum InfiniBand's ability to deliver exceptionally"
        }
    },
    {
        "chunk_id": "e7748f89-d86b-42cb-be42-57933c9e8819",
        "text": "InfiniBand's ability to deliver exceptionally fast data transfer speeds while minimizing latency. By focusing on rack-level or rail-specific networking, these systems reduce the distance data needs to travel and decrease the chances of congestion in the network, enabling smoother and faster data processing.  This optimization is especially valuable for customers that have compute-intensive workloads, such as those in high-performance computing (HPC), artificial intelligence, and deep learning",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 13,
            "chunk_id": "e7748f89-d86b-42cb-be42-57933c9e8819",
            "embedding_model": "text-embedding-3-large",
            "text": "InfiniBand's ability to deliver exceptionally fast data transfer speeds while minimizing latency. By focusing on rack-level or rail-specific networking, these systems reduce the distance data needs to travel and decrease the chances of congestion in the network, enabling smoother and faster data processing.  This optimization is especially valuable for customers that have compute-intensive workloads, such as those in high-performance computing (HPC), artificial intelligence, and deep learning"
        }
    },
    {
        "chunk_id": "9e5762e2-4743-4e92-b516-4ec875b7164d",
        "text": "(HPC), artificial intelligence, and deep learning environments, where rapid communication between nodes is critical. Rail-Optimized NVIDIA Quantum InfiniBand networks support direct communication channels between servers, allowing data centers to achieve consistent performance and scalability as they grow. Our engineers are skilled in optimizing our networks so you get the absolute best performance.  **Fast Connectivity to Storage Resources** Cirrascale provides options for its customers to",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 13,
            "chunk_id": "9e5762e2-4743-4e92-b516-4ec875b7164d",
            "embedding_model": "text-embedding-3-large",
            "text": "(HPC), artificial intelligence, and deep learning environments, where rapid communication between nodes is critical. Rail-Optimized NVIDIA Quantum InfiniBand networks support direct communication channels between servers, allowing data centers to achieve consistent performance and scalability as they grow. Our engineers are skilled in optimizing our networks so you get the absolute best performance.  **Fast Connectivity to Storage Resources** Cirrascale provides options for its customers to"
        }
    },
    {
        "chunk_id": "98c50bee-7819-4d37-9aa6-ac177e17281f",
        "text": "Cirrascale provides options for its customers to connect their dedicated multi-accelerator cloud servers to the industry's fastest, ultra high speed NVMe Flash storage from WEKA for the fastest available feeding of large deep learning and AI training, fine-tuning, and inference workloads requiring exceptionally high IOPS per server and centralized access. The WEKA Data Platform is certified as a high-performance data store solution for NVIDIA Cloud Partners like Cirrascale. ​ ​ **Private",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 13,
            "chunk_id": "98c50bee-7819-4d37-9aa6-ac177e17281f",
            "embedding_model": "text-embedding-3-large",
            "text": "Cirrascale provides options for its customers to connect their dedicated multi-accelerator cloud servers to the industry's fastest, ultra high speed NVMe Flash storage from WEKA for the fastest available feeding of large deep learning and AI training, fine-tuning, and inference workloads requiring exceptionally high IOPS per server and centralized access. The WEKA Data Platform is certified as a high-performance data store solution for NVIDIA Cloud Partners like Cirrascale. ​ ​ **Private"
        }
    },
    {
        "chunk_id": "49b73660-35a1-42c0-89b9-0afe1c954632",
        "text": "Cloud Partners like Cirrascale. ​ ​ **Private Networking** Private Networking enables our multi-accelerator cloud servers to communicate with other cloud servers in the same data center. Systems can be clustered together for replication, larger job   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 13,
            "chunk_id": "49b73660-35a1-42c0-89b9-0afe1c954632",
            "embedding_model": "text-embedding-3-large",
            "text": "Cloud Partners like Cirrascale. ​ ​ **Private Networking** Private Networking enables our multi-accelerator cloud servers to communicate with other cloud servers in the same data center. Systems can be clustered together for replication, larger job   -----"
        }
    },
    {
        "chunk_id": "7453cb2b-07a0-460f-be81-872a7dab8711",
        "text": "analysis, or more. Additionally, private networked servers can connect to the same storage resources making the delivery and sharing of data across nodes easier than ever.  **Guaranteed Uptime** Cirrascale Cloud Services has built its entire high-availability network around top-of-the-line providers in our state-of-the-art West, Central, and East data centers. We provide an uptime SLA around network, power and server availability. If we fail to hit our target, just call us and we'll credit you",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 14,
            "chunk_id": "7453cb2b-07a0-460f-be81-872a7dab8711",
            "embedding_model": "text-embedding-3-large",
            "text": "analysis, or more. Additionally, private networked servers can connect to the same storage resources making the delivery and sharing of data across nodes easier than ever.  **Guaranteed Uptime** Cirrascale Cloud Services has built its entire high-availability network around top-of-the-line providers in our state-of-the-art West, Central, and East data centers. We provide an uptime SLA around network, power and server availability. If we fail to hit our target, just call us and we'll credit you"
        }
    },
    {
        "chunk_id": "c3105142-92d3-4089-97a2-28bfd864343d",
        "text": "hit our target, just call us and we'll credit you based on the amount of time your servers were unavailable.   -----",
        "metadata": {
            "parent_document_id": "Products & Services.pdf",
            "parent_content_hash": "63e3fb0ad172ebf98eb1aefb15879f3766d8d2057b3db115ebcc7941cecc007c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Products & Services.pdf",
            "page_number": 14,
            "chunk_id": "c3105142-92d3-4089-97a2-28bfd864343d",
            "embedding_model": "text-embedding-3-large",
            "text": "hit our target, just call us and we'll credit you based on the amount of time your servers were unavailable.   -----"
        }
    },
    {
        "chunk_id": "d47f8abf-652e-4f3c-9676-57baafc3ce66",
        "text": "# Ai2 Drives Open-Source AI Innovation with NVIDIA Hopper GPUs and Cirrascale Cloud Services  ## “The most capable open  source AI model with visual  abilities yet.” [1]  This was not a headline Ai2 received when model  development was fragmented across multiple data  centers.  But it *was* their dream.  Ai2 is a nonprofit research institute dedicated to developing fully open source AI solutions that improve the work and lives of people around the world. They’d made incredible progress training",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 1,
            "chunk_id": "d47f8abf-652e-4f3c-9676-57baafc3ce66",
            "embedding_model": "text-embedding-3-large",
            "text": "# Ai2 Drives Open-Source AI Innovation with NVIDIA Hopper GPUs and Cirrascale Cloud Services  ## “The most capable open  source AI model with visual  abilities yet.” [1]  This was not a headline Ai2 received when model  development was fragmented across multiple data  centers.  But it *was* their dream.  Ai2 is a nonprofit research institute dedicated to developing fully open source AI solutions that improve the work and lives of people around the world. They’d made incredible progress training"
        }
    },
    {
        "chunk_id": "1c023201-5e62-4637-b723-9ba5b3e24c92",
        "text": "world. They’d made incredible progress training increasingly powerful models, especially considering the limits of the resources at hand. What they needed next wasn’t just more compute power but a scalable, forward-thinking strategy to launch Ai2 into the next chapter of open  source research and innovation.  “Ai2’s scientists and engineers were ready to  make big moves in the truly open AI space. We  have expertise across the entire stack, but we  were lacking the right infrastructure to meet",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 1,
            "chunk_id": "1c023201-5e62-4637-b723-9ba5b3e24c92",
            "embedding_model": "text-embedding-3-large",
            "text": "world. They’d made incredible progress training increasingly powerful models, especially considering the limits of the resources at hand. What they needed next wasn’t just more compute power but a scalable, forward-thinking strategy to launch Ai2 into the next chapter of open  source research and innovation.  “Ai2’s scientists and engineers were ready to  make big moves in the truly open AI space. We  have expertise across the entire stack, but we  were lacking the right infrastructure to meet"
        }
    },
    {
        "chunk_id": "f97dd540-0d85-466a-ba32-ff77adf88db8",
        "text": "were lacking the right infrastructure to meet  our needs,” says Michael Schmitz, Director of  Engineering at Ai2.  They needed a company that could offer the flexibility to design a best-in-class setup for their NVIDIA Hopper GPU cluster—with the headroom to scale as they grew over time. They were not looking for the typical handsoff cloud provider who’d sell them hours, but provide little to no support. Rather, Ai2 needed a trusted partner in cocreating custom, highly performant AI",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 1,
            "chunk_id": "f97dd540-0d85-466a-ba32-ff77adf88db8",
            "embedding_model": "text-embedding-3-large",
            "text": "were lacking the right infrastructure to meet  our needs,” says Michael Schmitz, Director of  Engineering at Ai2.  They needed a company that could offer the flexibility to design a best-in-class setup for their NVIDIA Hopper GPU cluster—with the headroom to scale as they grew over time. They were not looking for the typical handsoff cloud provider who’d sell them hours, but provide little to no support. Rather, Ai2 needed a trusted partner in cocreating custom, highly performant AI"
        }
    },
    {
        "chunk_id": "cb29cb60-56ec-41fa-a25a-f57e0649150b",
        "text": "in cocreating custom, highly performant AI infrastructure.  Cirrascale Cloud Services   1     -----",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 1,
            "chunk_id": "cb29cb60-56ec-41fa-a25a-f57e0649150b",
            "embedding_model": "text-embedding-3-large",
            "text": "in cocreating custom, highly performant AI infrastructure.  Cirrascale Cloud Services   1     -----"
        }
    },
    {
        "chunk_id": "d15eb88e-07d9-497d-8aed-929d0f836067",
        "text": "#### Cirrascale Cloud Services was an easy choice  The Cirrascale team had an existing relationship with Ai2, having deployed an initial NVIDIA GPU cluster for them. They had witnessed firsthand the evolution of this research institute as they trained increasingly larger models and consistently pushed compute boundaries. ###### “We tried to anticipate where they’re going to be in a year   and make sure we took that into account when architecting   a solution for them,” says David Driggers, CTO",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "d15eb88e-07d9-497d-8aed-929d0f836067",
            "embedding_model": "text-embedding-3-large",
            "text": "#### Cirrascale Cloud Services was an easy choice  The Cirrascale team had an existing relationship with Ai2, having deployed an initial NVIDIA GPU cluster for them. They had witnessed firsthand the evolution of this research institute as they trained increasingly larger models and consistently pushed compute boundaries. ###### “We tried to anticipate where they’re going to be in a year   and make sure we took that into account when architecting   a solution for them,” says David Driggers, CTO"
        }
    },
    {
        "chunk_id": "a9203b17-0767-41df-a42c-52301c42944e",
        "text": "a solution for them,” says David Driggers, CTO of Cirrascale.  Key to Ai2’s confidence in Cirrascale was their dedication to customize and optimize throughout the process, ensuring a successful deployment and a solution that would supercharge Ai2’s capabilities for their current needs and future growth.   growth  #### Collaborating as true partners  Unique to Cirrascale was their flexibility as a boutique hybrid cloud provider to customize a solution tailored to their customer’s needs. For",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "a9203b17-0767-41df-a42c-52301c42944e",
            "embedding_model": "text-embedding-3-large",
            "text": "a solution for them,” says David Driggers, CTO of Cirrascale.  Key to Ai2’s confidence in Cirrascale was their dedication to customize and optimize throughout the process, ensuring a successful deployment and a solution that would supercharge Ai2’s capabilities for their current needs and future growth.   growth  #### Collaborating as true partners  Unique to Cirrascale was their flexibility as a boutique hybrid cloud provider to customize a solution tailored to their customer’s needs. For"
        }
    },
    {
        "chunk_id": "7c8ba7d3-9aca-4c9a-b8a6-5960594738c1",
        "text": "solution tailored to their customer’s needs. For Ai2, this meant enabling them to purchase a portion of their hardware while maintaining a longer-term relationship with Cirrascale for setup, configuration, and ongoing management and optimization. ###### “We also set up a live channel with Ai2   where we can maintain a regular dialogue,   checking in to make sure everything is   going well and supporting them if anything   comes up,” says Driggers.  This way, Cirrascale is ready to step in and",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "7c8ba7d3-9aca-4c9a-b8a6-5960594738c1",
            "embedding_model": "text-embedding-3-large",
            "text": "solution tailored to their customer’s needs. For Ai2, this meant enabling them to purchase a portion of their hardware while maintaining a longer-term relationship with Cirrascale for setup, configuration, and ongoing management and optimization. ###### “We also set up a live channel with Ai2   where we can maintain a regular dialogue,   checking in to make sure everything is   going well and supporting them if anything   comes up,” says Driggers.  This way, Cirrascale is ready to step in and"
        }
    },
    {
        "chunk_id": "df0a3c90-3804-46cb-b52c-fcea2bd5fe2a",
        "text": "This way, Cirrascale is ready to step in and manage technical needs, letting Ai2 focus on what they do best: building breakthrough AI aimed at solving the world’s biggest challenges. ##### THE SPECS  #### Designing a complete solution for efficiency and reliability  Ai2 knew they wanted the NVIDIA accelerated computing platform and recognized that Cirrascale offered a much better storage option than the competition. Beyond that, they trusted Cirrascale to recommend the rest, from networking",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "df0a3c90-3804-46cb-b52c-fcea2bd5fe2a",
            "embedding_model": "text-embedding-3-large",
            "text": "This way, Cirrascale is ready to step in and manage technical needs, letting Ai2 focus on what they do best: building breakthrough AI aimed at solving the world’s biggest challenges. ##### THE SPECS  #### Designing a complete solution for efficiency and reliability  Ai2 knew they wanted the NVIDIA accelerated computing platform and recognized that Cirrascale offered a much better storage option than the competition. Beyond that, they trusted Cirrascale to recommend the rest, from networking"
        }
    },
    {
        "chunk_id": "582ab2dc-de86-4777-aa78-4e71c187ab04",
        "text": "Cirrascale to recommend the rest, from networking setup to infrastructure. Cirrascale ultimately proposed a comprehensive solution that prioritized business continuity and delivered as much performance as possible within the budget. Because of the way the team built the solution, selected materials, and set up the data centers, Ai2 is experiencing much higher job completion than they would have seen from traditional cloud providers. ###### “Cirrascale has been fantastic because of their",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "582ab2dc-de86-4777-aa78-4e71c187ab04",
            "embedding_model": "text-embedding-3-large",
            "text": "Cirrascale to recommend the rest, from networking setup to infrastructure. Cirrascale ultimately proposed a comprehensive solution that prioritized business continuity and delivered as much performance as possible within the budget. Because of the way the team built the solution, selected materials, and set up the data centers, Ai2 is experiencing much higher job completion than they would have seen from traditional cloud providers. ###### “Cirrascale has been fantastic because of their"
        }
    },
    {
        "chunk_id": "9c2a2c71-b225-4048-a837-e6c3b21fd140",
        "text": "“Cirrascale has been fantastic because of their willingness to customize every aspect of our setup,” says Schmitz.  A key challenge for Ai2 was that they anticipated their workloads expanding considerably as they grew. Cirrascale addressed this by reserving space in their data center, ensuring Ai2 can seamlessly expand their compute capacity and adopt emerging technologies as  their needs evolve.  The expansion has already begun, with Cirrascale deploying many more NVIDIA GPU clusters to",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "9c2a2c71-b225-4048-a837-e6c3b21fd140",
            "embedding_model": "text-embedding-3-large",
            "text": "“Cirrascale has been fantastic because of their willingness to customize every aspect of our setup,” says Schmitz.  A key challenge for Ai2 was that they anticipated their workloads expanding considerably as they grew. Cirrascale addressed this by reserving space in their data center, ensuring Ai2 can seamlessly expand their compute capacity and adopt emerging technologies as  their needs evolve.  The expansion has already begun, with Cirrascale deploying many more NVIDIA GPU clusters to"
        }
    },
    {
        "chunk_id": "a25d3087-32f3-423f-95f9-0225cf3fde61",
        "text": "deploying many more NVIDIA GPU clusters to augment the initial cluster for specific needs. As part of their ongoing efforts to remain at the cutting edge while reducing TCO, Ai2 is also pursuing an ultra-efficient  NVIDIA HGX B200 cluster.   The main AI training cluster: 1,024 NVIDIA  Hopper GPUs  Storage: Two-tiered multi-petabyte Weka.io storage cluster   Networking: 3200 Gbps NVIDIA Quantum-2 InfiniBand Platform  Data center: State-of the-art water-cooled  facility in Austin, TX   Cirrascale",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "a25d3087-32f3-423f-95f9-0225cf3fde61",
            "embedding_model": "text-embedding-3-large",
            "text": "deploying many more NVIDIA GPU clusters to augment the initial cluster for specific needs. As part of their ongoing efforts to remain at the cutting edge while reducing TCO, Ai2 is also pursuing an ultra-efficient  NVIDIA HGX B200 cluster.   The main AI training cluster: 1,024 NVIDIA  Hopper GPUs  Storage: Two-tiered multi-petabyte Weka.io storage cluster   Networking: 3200 Gbps NVIDIA Quantum-2 InfiniBand Platform  Data center: State-of the-art water-cooled  facility in Austin, TX   Cirrascale"
        }
    },
    {
        "chunk_id": "af52fe71-6608-427b-a349-1ea5c37fae8e",
        "text": "water-cooled  facility in Austin, TX   Cirrascale Cloud Services 2   -----",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 2,
            "chunk_id": "af52fe71-6608-427b-a349-1ea5c37fae8e",
            "embedding_model": "text-embedding-3-large",
            "text": "water-cooled  facility in Austin, TX   Cirrascale Cloud Services 2   -----"
        }
    },
    {
        "chunk_id": "4d979c3c-9f4d-4925-97ee-fc28f481465c",
        "text": "#### Empowering AI breakthroughs to solve the world’s biggest problems  These days, headlines about “redefining LLM innovation” [2] and “driving ‘critical shift’ in AI development” [3] are the norm for Ai2. ###### “The new cluster is completely transformational   for the company. And we have a long ramp   for being able to grow our presence in the data   center,” says Schmitz.   They now have the infrastructure to power the training of large scale, truly open models with more parameters, more",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 3,
            "chunk_id": "4d979c3c-9f4d-4925-97ee-fc28f481465c",
            "embedding_model": "text-embedding-3-large",
            "text": "#### Empowering AI breakthroughs to solve the world’s biggest problems  These days, headlines about “redefining LLM innovation” [2] and “driving ‘critical shift’ in AI development” [3] are the norm for Ai2. ###### “The new cluster is completely transformational   for the company. And we have a long ramp   for being able to grow our presence in the data   center,” says Schmitz.   They now have the infrastructure to power the training of large scale, truly open models with more parameters, more"
        }
    },
    {
        "chunk_id": "5acad8c0-e71f-46b8-8445-3329c3e629ee",
        "text": "truly open models with more parameters, more data, and in shorter amounts of time. This has enabled Ai2 to make leaps and bounds with their large language and multimodal models like Molmo, OLMo, and Tülu 3, cementing their position as a driving force in the open-source AI movement.  #### Enabling open-source AI initiatives  to compete  The AI world moves fast. With a scalable, flexible infrastructure designed to grow alongside their workloads, Ai2 is equipped to keep up.  This partnership with",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 3,
            "chunk_id": "5acad8c0-e71f-46b8-8445-3329c3e629ee",
            "embedding_model": "text-embedding-3-large",
            "text": "truly open models with more parameters, more data, and in shorter amounts of time. This has enabled Ai2 to make leaps and bounds with their large language and multimodal models like Molmo, OLMo, and Tülu 3, cementing their position as a driving force in the open-source AI movement.  #### Enabling open-source AI initiatives  to compete  The AI world moves fast. With a scalable, flexible infrastructure designed to grow alongside their workloads, Ai2 is equipped to keep up.  This partnership with"
        }
    },
    {
        "chunk_id": "29a2b039-56df-4d75-9840-4e408f5dbb44",
        "text": "is equipped to keep up.  This partnership with Cirrascale ensures that, as Ai2 continues to push the boundaries of truly open AI, they’ll have the resources and capacity to compete, and the infrastructure support to transform their bold visions into world-changing realities.  [1 “The Most Capable Open Source AI Model Yet Could Supercharge AI Agents”](https://www.wired.com/story/molmo-open-source-multimodal-ai-model-allen-institute-agents/)  [2 “How OLMo From Ai2 Redefines LLM",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 3,
            "chunk_id": "29a2b039-56df-4d75-9840-4e408f5dbb44",
            "embedding_model": "text-embedding-3-large",
            "text": "is equipped to keep up.  This partnership with Cirrascale ensures that, as Ai2 continues to push the boundaries of truly open AI, they’ll have the resources and capacity to compete, and the infrastructure support to transform their bold visions into world-changing realities.  [1 “The Most Capable Open Source AI Model Yet Could Supercharge AI Agents”](https://www.wired.com/story/molmo-open-source-multimodal-ai-model-allen-institute-agents/)  [2 “How OLMo From Ai2 Redefines LLM"
        }
    },
    {
        "chunk_id": "ce68161d-e50e-4c7a-a809-5ab3a8047a48",
        "text": "[2 “How OLMo From Ai2 Redefines LLM Innovation”](https://www.forbes.com/sites/janakirammsv/2024/02/05/how-olmo-from-the-ai2-redefines-llm-innovation/?sh=734a0ca76147)  [3 “Allen Institute for AI releases ‘truly open source’ LLM to drive ‘critical shift’ in](https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/) [AI development”](https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/)   [5775 Kearny",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 3,
            "chunk_id": "ce68161d-e50e-4c7a-a809-5ab3a8047a48",
            "embedding_model": "text-embedding-3-large",
            "text": "[2 “How OLMo From Ai2 Redefines LLM Innovation”](https://www.forbes.com/sites/janakirammsv/2024/02/05/how-olmo-from-the-ai2-redefines-llm-innovation/?sh=734a0ca76147)  [3 “Allen Institute for AI releases ‘truly open source’ LLM to drive ‘critical shift’ in](https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/) [AI development”](https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/)   [5775 Kearny"
        }
    },
    {
        "chunk_id": "12692269-1aa5-4091-9bbf-754bbecc682a",
        "text": "[5775 Kearny Villa Road, San Diego, CA 92123 USA  Phone 888-942-3800  Web www.cirrascale.com](http://www.cirrascale.com)  ©2025, Cirrascale Cloud Services. All Rights Reserved. Cirrascale and the Cirrascale logo are registered trademarks of Cirrascale Cloud Services. NVIDIA is a trademark or registered trademark of NVIDIA Corporation or its subsidiaries in the United States and other countries. All other names or marks are property of their respective owners. No part of this document may be",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 3,
            "chunk_id": "12692269-1aa5-4091-9bbf-754bbecc682a",
            "embedding_model": "text-embedding-3-large",
            "text": "[5775 Kearny Villa Road, San Diego, CA 92123 USA  Phone 888-942-3800  Web www.cirrascale.com](http://www.cirrascale.com)  ©2025, Cirrascale Cloud Services. All Rights Reserved. Cirrascale and the Cirrascale logo are registered trademarks of Cirrascale Cloud Services. NVIDIA is a trademark or registered trademark of NVIDIA Corporation or its subsidiaries in the United States and other countries. All other names or marks are property of their respective owners. No part of this document may be"
        }
    },
    {
        "chunk_id": "9afa2021-efac-4666-ac0f-f42c4d186fa8",
        "text": "owners. No part of this document may be reproduced without consent from Cirrascale Cloud Services. Technical specifications and pricing subject to change without notice.   -----",
        "metadata": {
            "parent_document_id": "Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "parent_content_hash": "26c46453c5f23a30a0380a89cdb64047985dc613f09712b0b638c15804dc5a92",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Cirrascale-Ai2-CaseStudy-H (4).pdf",
            "page_number": 3,
            "chunk_id": "9afa2021-efac-4666-ac0f-f42c4d186fa8",
            "embedding_model": "text-embedding-3-large",
            "text": "owners. No part of this document may be reproduced without consent from Cirrascale Cloud Services. Technical specifications and pricing subject to change without notice.   -----"
        }
    },
    {
        "chunk_id": "86319e41-0e3f-48e8-a45f-b356f807ed50",
        "text": "## Core Offerings and Services ### The Cirrascale AI Innovation Cloud  Our flagship AI Innovation Cloud is a leading platform for  AI development and deployment. Unlike traditional cloud  providers, Cirrascale Cloud Services offers:    - The only cloud service providing access to every  leading AI accelerator, including NVIDIA, AMD,  Cerebras, Qualcomm, and more.  # Empowering the Future of AI Innovation #### Pushing the Boundaries of What’s Possible in AI Cirrascale stands at the forefront of",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 1,
            "chunk_id": "86319e41-0e3f-48e8-a45f-b356f807ed50",
            "embedding_model": "text-embedding-3-large",
            "text": "## Core Offerings and Services ### The Cirrascale AI Innovation Cloud  Our flagship AI Innovation Cloud is a leading platform for  AI development and deployment. Unlike traditional cloud  providers, Cirrascale Cloud Services offers:    - The only cloud service providing access to every  leading AI accelerator, including NVIDIA, AMD,  Cerebras, Qualcomm, and more.  # Empowering the Future of AI Innovation #### Pushing the Boundaries of What’s Possible in AI Cirrascale stands at the forefront of"
        }
    },
    {
        "chunk_id": "3bbf875c-bf95-4540-b57b-259366c690cd",
        "text": "in AI Cirrascale stands at the forefront of cloud innovation, providing purpose-built infrastructure solutions designed to meet the demanding requirements of modern AI, machine learning, inference, and high performance computing workloads. Our AI Innovation Cloud offers cost-effective, high-speed cloud solutions with the features you need. As a specialized cloud services provider, we deliver unmatched performance, scalability, and expertise to organizations pushing the boundaries of what’s",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 1,
            "chunk_id": "3bbf875c-bf95-4540-b57b-259366c690cd",
            "embedding_model": "text-embedding-3-large",
            "text": "in AI Cirrascale stands at the forefront of cloud innovation, providing purpose-built infrastructure solutions designed to meet the demanding requirements of modern AI, machine learning, inference, and high performance computing workloads. Our AI Innovation Cloud offers cost-effective, high-speed cloud solutions with the features you need. As a specialized cloud services provider, we deliver unmatched performance, scalability, and expertise to organizations pushing the boundaries of what’s"
        }
    },
    {
        "chunk_id": "744c036a-f2d1-4a71-8773-d74cc9430b63",
        "text": "to organizations pushing the boundaries of what’s possible in AI and computational technology. ### Advanced Cloud Infrastructure  Cirrascale’s AI Innovation Cloud infrastructure is engineered  for performance:       - 25Gb/50Gb/100Gb Ethernet or 200Gb HDR and 400Gb  NDR NVIDIA Quantum-2 InfiniBand.        - Lightning-fast NVMe hot-tier storage solutions.        - Interconnect to your existing infrastructure, either on premises or with a hyperscale cloud provider like AWS,  GCP, Azure or Oracle.",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 1,
            "chunk_id": "744c036a-f2d1-4a71-8773-d74cc9430b63",
            "embedding_model": "text-embedding-3-large",
            "text": "to organizations pushing the boundaries of what’s possible in AI and computational technology. ### Advanced Cloud Infrastructure  Cirrascale’s AI Innovation Cloud infrastructure is engineered  for performance:       - 25Gb/50Gb/100Gb Ethernet or 200Gb HDR and 400Gb  NDR NVIDIA Quantum-2 InfiniBand.        - Lightning-fast NVMe hot-tier storage solutions.        - Interconnect to your existing infrastructure, either on premises or with a hyperscale cloud provider like AWS,  GCP, Azure or Oracle."
        }
    },
    {
        "chunk_id": "12f5f0fe-11cb-4ac3-bad2-9e36927d5a93",
        "text": "cloud provider like AWS,  GCP, Azure or Oracle.      - Purpose-built infrastructure optimized for Generative  AI, LLMs, and complex AI workloads.    - Industry-leading power capacity supporting the  highest-density GPU configurations.    - Dedicated, bare-metal servers ensuring maximum  performance without virtualization. ### Cirrascale Inference Platform for Enterprise  Optimized for real-time AI inferencing, our platform ensures  low-latency, high-efficiency performance at enterprise scale.",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 1,
            "chunk_id": "12f5f0fe-11cb-4ac3-bad2-9e36927d5a93",
            "embedding_model": "text-embedding-3-large",
            "text": "cloud provider like AWS,  GCP, Azure or Oracle.      - Purpose-built infrastructure optimized for Generative  AI, LLMs, and complex AI workloads.    - Industry-leading power capacity supporting the  highest-density GPU configurations.    - Dedicated, bare-metal servers ensuring maximum  performance without virtualization. ### Cirrascale Inference Platform for Enterprise  Optimized for real-time AI inferencing, our platform ensures  low-latency, high-efficiency performance at enterprise scale."
        }
    },
    {
        "chunk_id": "41e680fb-292f-4acc-a1a3-931c34542686",
        "text": "performance at enterprise scale.    - NVIDIA Blackwell B200, B40, and H200 GPUs at debut.    - Dynamically balances workloads across regions.    - Serverless deployments that provide an instant AI  Model Pipeline.    - Pre-compiled foundational models optimized for  underlying accelerators.    - Web console-based deployment and configuration.    - API Access to the AI model utilizing OpenAI API’s.    - Supports fine-tuned models and custom weights.    - Priced by token volume for the given AI",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 1,
            "chunk_id": "41e680fb-292f-4acc-a1a3-931c34542686",
            "embedding_model": "text-embedding-3-large",
            "text": "performance at enterprise scale.    - NVIDIA Blackwell B200, B40, and H200 GPUs at debut.    - Dynamically balances workloads across regions.    - Serverless deployments that provide an instant AI  Model Pipeline.    - Pre-compiled foundational models optimized for  underlying accelerators.    - Web console-based deployment and configuration.    - API Access to the AI model utilizing OpenAI API’s.    - Supports fine-tuned models and custom weights.    - Priced by token volume for the given AI"
        }
    },
    {
        "chunk_id": "d6f55e63-7abe-4c2e-b492-22084ba99376",
        "text": "- Priced by token volume for the given AI Model used in  the pipeline.      - Kubernetes and cluster management expertise.    - Comprehensive network management including DNS  and out-of-band management. ### No-Surprises Cloud Services Billing  Transparent pricing that lets you focus on innovation:    - Simple, flat-rate billing model.    - No hidden ingress or egress fees.    - Predictable costs for long-term planning.    - Discounts for extended and large commitments. ### Premium Managed",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 1,
            "chunk_id": "d6f55e63-7abe-4c2e-b492-22084ba99376",
            "embedding_model": "text-embedding-3-large",
            "text": "- Priced by token volume for the given AI Model used in  the pipeline.      - Kubernetes and cluster management expertise.    - Comprehensive network management including DNS  and out-of-band management. ### No-Surprises Cloud Services Billing  Transparent pricing that lets you focus on innovation:    - Simple, flat-rate billing model.    - No hidden ingress or egress fees.    - Predictable costs for long-term planning.    - Discounts for extended and large commitments. ### Premium Managed"
        }
    },
    {
        "chunk_id": "71594772-2b82-49ac-b2d5-f486babac994",
        "text": "and large commitments. ### Premium Managed Services  For enterprises requiring end-to-end cloud management, our  white-glove services delivers comprehensive support.    - 2N power redundancy with A+B fully managed service.    - Enterprise-grade security with access control.    - SSAE-16 / ISAE, SOC1 Type 2 and SOC2 Type 2  certified secure environments.    - Expert installation, monitoring, and break/fix support.    - Streamlined deployment with automated provisioning  capabilities.   -----",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 1,
            "chunk_id": "71594772-2b82-49ac-b2d5-f486babac994",
            "embedding_model": "text-embedding-3-large",
            "text": "and large commitments. ### Premium Managed Services  For enterprises requiring end-to-end cloud management, our  white-glove services delivers comprehensive support.    - 2N power redundancy with A+B fully managed service.    - Enterprise-grade security with access control.    - SSAE-16 / ISAE, SOC1 Type 2 and SOC2 Type 2  certified secure environments.    - Expert installation, monitoring, and break/fix support.    - Streamlined deployment with automated provisioning  capabilities.   -----"
        }
    },
    {
        "chunk_id": "98c67173-cad4-43e3-aa04-fd24e0c13df9",
        "text": "## Strategic Technology Partnerships with Today’s Latest AI Accelerators  The Cirrascale AI Innovation Cloud stands apart as the only cloud service where customers can access and deploy workloads  across every leading AI accelerator technology in a single environment. Through strategic partnerships with industry leaders,  we deliver a comprehensive ecosystem of accelerator options including the NVIDIA B200 and H200 TensorCore accelerators,  the AMD Instinct MI300x and MI350x accelerators, the",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "98c67173-cad4-43e3-aa04-fd24e0c13df9",
            "embedding_model": "text-embedding-3-large",
            "text": "## Strategic Technology Partnerships with Today’s Latest AI Accelerators  The Cirrascale AI Innovation Cloud stands apart as the only cloud service where customers can access and deploy workloads  across every leading AI accelerator technology in a single environment. Through strategic partnerships with industry leaders,  we deliver a comprehensive ecosystem of accelerator options including the NVIDIA B200 and H200 TensorCore accelerators,  the AMD Instinct MI300x and MI350x accelerators, the"
        }
    },
    {
        "chunk_id": "b6bab3fa-f487-477d-9b5c-f9d2ff402c4e",
        "text": "AMD Instinct MI300x and MI350x accelerators, the Cerebras CS-2 WSE, and the Qualcomm Cloud AI 100 Ultra. This diverse  portfolio ensures customers can test, optimize and select the best architecture for their specific workloads — from training to  fine-tuning to inference — without being locked in to a single vendor’s ecosystem. That’s the Cirrascale advantage. ## Industry Solutions  ### Generative AI and Large Language Models    - Purpose-built infrastructure for training and  inferencing",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "b6bab3fa-f487-477d-9b5c-f9d2ff402c4e",
            "embedding_model": "text-embedding-3-large",
            "text": "AMD Instinct MI300x and MI350x accelerators, the Cerebras CS-2 WSE, and the Qualcomm Cloud AI 100 Ultra. This diverse  portfolio ensures customers can test, optimize and select the best architecture for their specific workloads — from training to  fine-tuning to inference — without being locked in to a single vendor’s ecosystem. That’s the Cirrascale advantage. ## Industry Solutions  ### Generative AI and Large Language Models    - Purpose-built infrastructure for training and  inferencing"
        }
    },
    {
        "chunk_id": "e7f2fd0c-b8af-4f3a-a68f-71cfc20cb1be",
        "text": "infrastructure for training and  inferencing generative AI models.    - Specialized solutions for pre-training, fine-tuning,  and inference.    - Support for leading frameworks including PyTorch,  TensorFlow, JAX, ONNX and more.    - Optimized for popular models like GPT, BERT, and  T5 variants and any other models available on  Hugging Face. ### Computer Vision and Autonomous Systems    - Optimized platforms for image classification,  object detection, and tracking.    - High-performance",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "e7f2fd0c-b8af-4f3a-a68f-71cfc20cb1be",
            "embedding_model": "text-embedding-3-large",
            "text": "infrastructure for training and  inferencing generative AI models.    - Specialized solutions for pre-training, fine-tuning,  and inference.    - Support for leading frameworks including PyTorch,  TensorFlow, JAX, ONNX and more.    - Optimized for popular models like GPT, BERT, and  T5 variants and any other models available on  Hugging Face. ### Computer Vision and Autonomous Systems    - Optimized platforms for image classification,  object detection, and tracking.    - High-performance"
        }
    },
    {
        "chunk_id": "ede9303c-1da4-43eb-8d7c-05cb416fae3f",
        "text": "detection, and tracking.    - High-performance infrastructure for robotics and  autonomous system development or validaton.    - Scalable solutions for training and deploying  computer vision models. ### High Performance Computing    - Advanced computational resources for scientific  research and simulation.    - Seamless integration of traditional HPC with  modern AI capabilities.    - Support for complex data analytics and  visualization workflows.  ## NVIDIA Inception Members  Cirrascale",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "ede9303c-1da4-43eb-8d7c-05cb416fae3f",
            "embedding_model": "text-embedding-3-large",
            "text": "detection, and tracking.    - High-performance infrastructure for robotics and  autonomous system development or validaton.    - Scalable solutions for training and deploying  computer vision models. ### High Performance Computing    - Advanced computational resources for scientific  research and simulation.    - Seamless integration of traditional HPC with  modern AI capabilities.    - Support for complex data analytics and  visualization workflows.  ## NVIDIA Inception Members  Cirrascale"
        }
    },
    {
        "chunk_id": "92510745-cc77-431e-b934-c013cb44bd94",
        "text": "## NVIDIA Inception Members  Cirrascale Cloud Services helps NVIDIA Inception  members get the most out of their program benefits.  Whether you’re a community or premier member, we  can assist in extending your benefits.  Cirrascale has been helping NVIDIA Inception  program members evolve faster by providing them  with unique benefits. By partnering with Cirrascale,  approved Inception members can purchase hardware  at preferred pricing levels, receive discounts on  cloud or managed services",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "92510745-cc77-431e-b934-c013cb44bd94",
            "embedding_model": "text-embedding-3-large",
            "text": "## NVIDIA Inception Members  Cirrascale Cloud Services helps NVIDIA Inception  members get the most out of their program benefits.  Whether you’re a community or premier member, we  can assist in extending your benefits.  Cirrascale has been helping NVIDIA Inception  program members evolve faster by providing them  with unique benefits. By partnering with Cirrascale,  approved Inception members can purchase hardware  at preferred pricing levels, receive discounts on  cloud or managed services"
        }
    },
    {
        "chunk_id": "4f89846d-a112-4cb9-9e33-97b1708038c8",
        "text": "receive discounts on  cloud or managed services provided by Cirrascale,  and partner with us to receive referral discounts for  other startups you refer.  Cirrascale Cloud Services works closely with NVIDIA  and your assigned dedicated relationship manager to  provide you with the best experience as an Inception  member. ## Need Specialized Services?  At Cirrascale, we take pride in being flexible and  receptive to our customer’s individualized needs. We  understand that not every customer has",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "4f89846d-a112-4cb9-9e33-97b1708038c8",
            "embedding_model": "text-embedding-3-large",
            "text": "receive discounts on  cloud or managed services provided by Cirrascale,  and partner with us to receive referral discounts for  other startups you refer.  Cirrascale Cloud Services works closely with NVIDIA  and your assigned dedicated relationship manager to  provide you with the best experience as an Inception  member. ## Need Specialized Services?  At Cirrascale, we take pride in being flexible and  receptive to our customer’s individualized needs. We  understand that not every customer has"
        }
    },
    {
        "chunk_id": "2c69aee1-0e44-4420-8a50-8f15ac33ec99",
        "text": "needs. We  understand that not every customer has the same  requirements. If you need some additional services  that are not discussed above, please reach out to us.   Cirrascale Cloud Services 5775 Kearny Villa Road, San Diego, CA 92123 USA  Phone 888-942-3800  Web www.cirrascale.com   ©2025, Cirrascale Cloud Services. All Rights Reserved. Cirrascale and the Cirrascale logo are registered trademarks of Cirrascale Cloud Services. NVIDIA is a trademark or registered trademark of NVIDIA",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "2c69aee1-0e44-4420-8a50-8f15ac33ec99",
            "embedding_model": "text-embedding-3-large",
            "text": "needs. We  understand that not every customer has the same  requirements. If you need some additional services  that are not discussed above, please reach out to us.   Cirrascale Cloud Services 5775 Kearny Villa Road, San Diego, CA 92123 USA  Phone 888-942-3800  Web www.cirrascale.com   ©2025, Cirrascale Cloud Services. All Rights Reserved. Cirrascale and the Cirrascale logo are registered trademarks of Cirrascale Cloud Services. NVIDIA is a trademark or registered trademark of NVIDIA"
        }
    },
    {
        "chunk_id": "675f51e5-cd02-40b3-8b4e-48be37756bde",
        "text": "is a trademark or registered trademark of NVIDIA Corporation or its subsidiaries in the United States and other countries. All other names or marks are property of their respective owners. No part of this document may be reproduced without consent from Cirrascale Cloud Services. Technical specifications and pricing subject to change without notice.   CSM001 - REV M - 3/2025   -----",
        "metadata": {
            "parent_document_id": "CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "parent_content_hash": "691fc0337f091b65f5ddb878404796e994e5347f802606a50efc53e2528914f9",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/CCS-CLOUD-SERVICES-CSM001-REV-M (1).pdf",
            "page_number": 2,
            "chunk_id": "675f51e5-cd02-40b3-8b4e-48be37756bde",
            "embedding_model": "text-embedding-3-large",
            "text": "is a trademark or registered trademark of NVIDIA Corporation or its subsidiaries in the United States and other countries. All other names or marks are property of their respective owners. No part of this document may be reproduced without consent from Cirrascale Cloud Services. Technical specifications and pricing subject to change without notice.   CSM001 - REV M - 3/2025   -----"
        }
    },
    {
        "chunk_id": "fa7eab6a-1003-4b91-a8b4-cae4a0c873f8",
        "text": "## **Qualcomm Cloud AI 100 **  Optimized inference for leading AI models, up to 5x performance of competing solutions.  Qualcomm Cloud AI, as part of the Cirrascale AI Innovation Cloud, utilizing the Qualcomm Cloud AI 100 Ultra, delivers the performance and power efficiency necessary to deploy and  accelerate AI inference at scale.  Now providing bare-metal access and the new Inference Cloud powered by Qualcomm.  **Qualcomm Cloud AI 100 Ultra Solutions** Providing industry leading",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 2,
            "chunk_id": "fa7eab6a-1003-4b91-a8b4-cae4a0c873f8",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Qualcomm Cloud AI 100 **  Optimized inference for leading AI models, up to 5x performance of competing solutions.  Qualcomm Cloud AI, as part of the Cirrascale AI Innovation Cloud, utilizing the Qualcomm Cloud AI 100 Ultra, delivers the performance and power efficiency necessary to deploy and  accelerate AI inference at scale.  Now providing bare-metal access and the new Inference Cloud powered by Qualcomm.  **Qualcomm Cloud AI 100 Ultra Solutions** Providing industry leading"
        }
    },
    {
        "chunk_id": "018ec588-e243-408a-93e7-0094f00e5199",
        "text": "100 Ultra Solutions** Providing industry leading performance-per-TCO$ spanning GenAI, including Large Language Models, as well as Natural Language Processing and Computer Vision. Unlocking new possibilities for Al applications in the cloud for model developers, Al inference solution providers, and enterprises.  **Purpose-Built Inferencing** Generative Al models being developed today, require robust, high-performance acceleration during development and training. However, when deploying a",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 2,
            "chunk_id": "018ec588-e243-408a-93e7-0094f00e5199",
            "embedding_model": "text-embedding-3-large",
            "text": "100 Ultra Solutions** Providing industry leading performance-per-TCO$ spanning GenAI, including Large Language Models, as well as Natural Language Processing and Computer Vision. Unlocking new possibilities for Al applications in the cloud for model developers, Al inference solution providers, and enterprises.  **Purpose-Built Inferencing** Generative Al models being developed today, require robust, high-performance acceleration during development and training. However, when deploying a"
        }
    },
    {
        "chunk_id": "b80315a6-5e61-4eff-a1e0-e11f4d506878",
        "text": "and training. However, when deploying a pre-built model for a service or enterprise offering, the main requirement is cost-effective inference, avoiding the high costs from devices that are optimized for training.  The Qualcomm Cloud Al Platform includes devices like the Cloud Al 100 Ultra, purpose-built for Generative Al. It accelerates inference for Large Language Models (LLMs), Natural Language Processing (NLP), and Computer Vision (CV).  **Inference Cloud powered by Qualcomm** Accelerate",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 2,
            "chunk_id": "b80315a6-5e61-4eff-a1e0-e11f4d506878",
            "embedding_model": "text-embedding-3-large",
            "text": "and training. However, when deploying a pre-built model for a service or enterprise offering, the main requirement is cost-effective inference, avoiding the high costs from devices that are optimized for training.  The Qualcomm Cloud Al Platform includes devices like the Cloud Al 100 Ultra, purpose-built for Generative Al. It accelerates inference for Large Language Models (LLMs), Natural Language Processing (NLP), and Computer Vision (CV).  **Inference Cloud powered by Qualcomm** Accelerate"
        }
    },
    {
        "chunk_id": "ace338ab-7cd8-40a4-b352-d513341de154",
        "text": "Cloud powered by Qualcomm** Accelerate generative AI development with ready-to-use applications and agents that enable production deployment with the Qualcomm AI Inference Suite.  **Customized Options Available** For specialized needs or enhanced scalability, Cirrascale offers the Qualcomm Cloud AI 100 Ultra in a bare-metal solution that enables deep integration of custom DevOps workforces with your inference requirements. We work with you to develop the solution you need.   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 2,
            "chunk_id": "ace338ab-7cd8-40a4-b352-d513341de154",
            "embedding_model": "text-embedding-3-large",
            "text": "Cloud powered by Qualcomm** Accelerate generative AI development with ready-to-use applications and agents that enable production deployment with the Qualcomm AI Inference Suite.  **Customized Options Available** For specialized needs or enhanced scalability, Cirrascale offers the Qualcomm Cloud AI 100 Ultra in a bare-metal solution that enables deep integration of custom DevOps workforces with your inference requirements. We work with you to develop the solution you need.   -----"
        }
    },
    {
        "chunk_id": "cad2781c-bb9a-4318-aaaa-09d7f620f352",
        "text": "## **AMD Instinct™ Series **  AMD Instinct Series accelerators, delivered in the Cirrascale AI Innovation Cloud, enable performance leadership that is uniquely well-suited to power even the most demanding AI and  HPC workloads.  We've partnered with AMD to offer their AMD Instinct Series accelerators in the cloud for customers to test, utilize and fully deploy. These accelerators provide exceptional compute performance, large memory density, high bandwidth memory, and support for specialized",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 4,
            "chunk_id": "cad2781c-bb9a-4318-aaaa-09d7f620f352",
            "embedding_model": "text-embedding-3-large",
            "text": "## **AMD Instinct™ Series **  AMD Instinct Series accelerators, delivered in the Cirrascale AI Innovation Cloud, enable performance leadership that is uniquely well-suited to power even the most demanding AI and  HPC workloads.  We've partnered with AMD to offer their AMD Instinct Series accelerators in the cloud for customers to test, utilize and fully deploy. These accelerators provide exceptional compute performance, large memory density, high bandwidth memory, and support for specialized"
        }
    },
    {
        "chunk_id": "009cccbb-06fa-46ef-b615-c6dbbb410c6b",
        "text": "bandwidth memory, and support for specialized data formats. AMD Instinct accelerators are built on AMD CDNA™ architecture, which features Matrix Core Technologies and supports a broad range of precision capabilities.  **AMD Benefits**  **AMD ROCm Software**  AMD ROCm™ is an open software stack including drivers, development tools, and APIs that enable GPU programming from low-level kernel to end-user applications. ROCm is optimized for Generative AI and HPC applications, and is easy to migrate",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 4,
            "chunk_id": "009cccbb-06fa-46ef-b615-c6dbbb410c6b",
            "embedding_model": "text-embedding-3-large",
            "text": "bandwidth memory, and support for specialized data formats. AMD Instinct accelerators are built on AMD CDNA™ architecture, which features Matrix Core Technologies and supports a broad range of precision capabilities.  **AMD Benefits**  **AMD ROCm Software**  AMD ROCm™ is an open software stack including drivers, development tools, and APIs that enable GPU programming from low-level kernel to end-user applications. ROCm is optimized for Generative AI and HPC applications, and is easy to migrate"
        }
    },
    {
        "chunk_id": "9a54ed8c-740d-4c03-8c5c-cf87bd152dc3",
        "text": "AI and HPC applications, and is easy to migrate existing code into.  ROCm enables AI and HPC application development across a broad range of demanding  workloads.  **AMD Infinity Fabric Technology** Cirrascale-hosted AMD Instinct series accelerators with advanced peer- to-peer I/O connectivity through a maximum of eight AMD Infinity Fabric™ links deliver up to 800 GB/s I/O bandwidth performance. With a cache-coherent solution using optimized AMD EPYC™ CPUs and Instinct accelerators, Infinity",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 4,
            "chunk_id": "9a54ed8c-740d-4c03-8c5c-cf87bd152dc3",
            "embedding_model": "text-embedding-3-large",
            "text": "AI and HPC applications, and is easy to migrate existing code into.  ROCm enables AI and HPC application development across a broad range of demanding  workloads.  **AMD Infinity Fabric Technology** Cirrascale-hosted AMD Instinct series accelerators with advanced peer- to-peer I/O connectivity through a maximum of eight AMD Infinity Fabric™ links deliver up to 800 GB/s I/O bandwidth performance. With a cache-coherent solution using optimized AMD EPYC™ CPUs and Instinct accelerators, Infinity"
        }
    },
    {
        "chunk_id": "6927f873-94b9-4a35-beab-f00d48bed7bb",
        "text": "EPYC™ CPUs and Instinct accelerators, Infinity Fabric unlocks the promise of unified computing, enabling a quick and simple on-ramp for CPU code to accelerated platforms.  **Discover the Benefits of AMD Instinct hosted by Cirracale**  **Optimal Performance at the Right Price**    - ​ High performance with larger memory than other acceleration offerings    - ​ Optimized for leading Generative AI models, including LLMs  **Ease of Use**    - ​ AMD drivers pre-installed and configured by Cirrascale",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 4,
            "chunk_id": "6927f873-94b9-4a35-beab-f00d48bed7bb",
            "embedding_model": "text-embedding-3-large",
            "text": "EPYC™ CPUs and Instinct accelerators, Infinity Fabric unlocks the promise of unified computing, enabling a quick and simple on-ramp for CPU code to accelerated platforms.  **Discover the Benefits of AMD Instinct hosted by Cirracale**  **Optimal Performance at the Right Price**    - ​ High performance with larger memory than other acceleration offerings    - ​ Optimized for leading Generative AI models, including LLMs  **Ease of Use**    - ​ AMD drivers pre-installed and configured by Cirrascale"
        }
    },
    {
        "chunk_id": "244fd849-6863-4b1a-a489-f2259c7c4520",
        "text": "pre-installed and configured by Cirrascale    - ​ ROCm software included for easy access to frameworks and tools    - ​ Hugging Face transformers supported out of the box    - ​ Highly scalable for the most demanding training, tuning and inference workloads  **Simple & Secure Cloud Operations**    - ​ Simple onboarding – No DevOps required    - ​ SDKs, storage and network are configured and ready to go   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 4,
            "chunk_id": "244fd849-6863-4b1a-a489-f2259c7c4520",
            "embedding_model": "text-embedding-3-large",
            "text": "pre-installed and configured by Cirrascale    - ​ ROCm software included for easy access to frameworks and tools    - ​ Hugging Face transformers supported out of the box    - ​ Highly scalable for the most demanding training, tuning and inference workloads  **Simple & Secure Cloud Operations**    - ​ Simple onboarding – No DevOps required    - ​ SDKs, storage and network are configured and ready to go   -----"
        }
    },
    {
        "chunk_id": "a986c130-a9de-47fb-b1b1-ecef1f86e112",
        "text": "**AMD Products**  **AMD Instinct MI300X**  AMD Instinct™ MI300X accelerators are uniquely well-suited to power even the most demanding AI and HPC workloads, offering exceptional compute performance, large memory density, high bandwidth memory, and support for specialized data formats.  AMD Instinct MI300X accelerators are built on AMD CDNA™ 3 architecture, which offers Matrix Core Technologies and support for a broad range of precision capabilities—from the highly efficient INT8 and FP8",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 5,
            "chunk_id": "a986c130-a9de-47fb-b1b1-ecef1f86e112",
            "embedding_model": "text-embedding-3-large",
            "text": "**AMD Products**  **AMD Instinct MI300X**  AMD Instinct™ MI300X accelerators are uniquely well-suited to power even the most demanding AI and HPC workloads, offering exceptional compute performance, large memory density, high bandwidth memory, and support for specialized data formats.  AMD Instinct MI300X accelerators are built on AMD CDNA™ 3 architecture, which offers Matrix Core Technologies and support for a broad range of precision capabilities—from the highly efficient INT8 and FP8"
        }
    },
    {
        "chunk_id": "4ccbe410-4d3b-428d-9060-4fe3d5b034a9",
        "text": "the highly efficient INT8 and FP8 (including sparsity support for AI) to the most demanding FP64 for HPC.  **AMD Instinct MI250**  The AMD Instinct MI250 accelerator brings customers the compute engine selected for the first U.S. Exascale supercomputer.  AMD Instinct MI250 accelerators are built on AMD CDNA™ architecture, which offers Matrix Core Technologies and support for a broad range of precision capabilities—from the highly efficient INT8 and FP8 to the most demanding FP64 for HPC.",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 5,
            "chunk_id": "4ccbe410-4d3b-428d-9060-4fe3d5b034a9",
            "embedding_model": "text-embedding-3-large",
            "text": "the highly efficient INT8 and FP8 (including sparsity support for AI) to the most demanding FP64 for HPC.  **AMD Instinct MI250**  The AMD Instinct MI250 accelerator brings customers the compute engine selected for the first U.S. Exascale supercomputer.  AMD Instinct MI250 accelerators are built on AMD CDNA™ architecture, which offers Matrix Core Technologies and support for a broad range of precision capabilities—from the highly efficient INT8 and FP8 to the most demanding FP64 for HPC."
        }
    },
    {
        "chunk_id": "85ed6e66-f7dd-4d11-a2eb-457f84cdf514",
        "text": "and FP8 to the most demanding FP64 for HPC.   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 5,
            "chunk_id": "85ed6e66-f7dd-4d11-a2eb-457f84cdf514",
            "embedding_model": "text-embedding-3-large",
            "text": "and FP8 to the most demanding FP64 for HPC.   -----"
        }
    },
    {
        "chunk_id": "5bc88cfc-cb06-424d-96c0-9a1e4fde8a56",
        "text": "## **The Cerebras AI Model Studio **  **Train GPT-Style Models 8x Faster Than Traditional Clouds at a Fraction of the Cost**  Hosted on the Cerebras Cloud @ Cirrascale, the Cerebras AI Model Studio is a purpose-built platform, optimized for training and fine-tuning large language models on dedicated clusters. It provides deterministic performance, requires no distributed computing headaches, and is push-button simple to start.  **The Cerebras AI Model Studio**  The Cerebras AI Model Studio is a",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 7,
            "chunk_id": "5bc88cfc-cb06-424d-96c0-9a1e4fde8a56",
            "embedding_model": "text-embedding-3-large",
            "text": "## **The Cerebras AI Model Studio **  **Train GPT-Style Models 8x Faster Than Traditional Clouds at a Fraction of the Cost**  Hosted on the Cerebras Cloud @ Cirrascale, the Cerebras AI Model Studio is a purpose-built platform, optimized for training and fine-tuning large language models on dedicated clusters. It provides deterministic performance, requires no distributed computing headaches, and is push-button simple to start.  **The Cerebras AI Model Studio**  The Cerebras AI Model Studio is a"
        }
    },
    {
        "chunk_id": "c8ea8cfc-8b7d-4574-9eda-a65ec8713e32",
        "text": "Model Studio**  The Cerebras AI Model Studio is a simple pay by the model computing service powered by dedicated clusters of Cerebras CS-2’s and hosted by Cirrascale Cloud Services. It is a purpose-built platform, optimized for training large language models on dedicated clusters of millions of cores. It provides deterministic performance, requires no distributed computing headaches, and is push-button simple to start.  **The Problem**  Training large Transformer models such as GPT and T5 on",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 7,
            "chunk_id": "c8ea8cfc-8b7d-4574-9eda-a65ec8713e32",
            "embedding_model": "text-embedding-3-large",
            "text": "Model Studio**  The Cerebras AI Model Studio is a simple pay by the model computing service powered by dedicated clusters of Cerebras CS-2’s and hosted by Cirrascale Cloud Services. It is a purpose-built platform, optimized for training large language models on dedicated clusters of millions of cores. It provides deterministic performance, requires no distributed computing headaches, and is push-button simple to start.  **The Problem**  Training large Transformer models such as GPT and T5 on"
        }
    },
    {
        "chunk_id": "c85c1297-3f1e-4e93-a523-62c654aa08d6",
        "text": "large Transformer models such as GPT and T5 on traditional cloud platforms can be painful, expensive, and time consuming. Gaining access to large instances typically offered in the cloud can often takes weeks just to get access. Networking, storage, and compute can cost extra, and setting up the environment is no joke. Models with tens of billions of parameters end up taking weeks to get going and months to train.  If you want to train in less time, you can attempt to reserve additional",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 7,
            "chunk_id": "c85c1297-3f1e-4e93-a523-62c654aa08d6",
            "embedding_model": "text-embedding-3-large",
            "text": "large Transformer models such as GPT and T5 on traditional cloud platforms can be painful, expensive, and time consuming. Gaining access to large instances typically offered in the cloud can often takes weeks just to get access. Networking, storage, and compute can cost extra, and setting up the environment is no joke. Models with tens of billions of parameters end up taking weeks to get going and months to train.  If you want to train in less time, you can attempt to reserve additional"
        }
    },
    {
        "chunk_id": "5c492910-5eaa-491b-8c71-04022e2c8abc",
        "text": "less time, you can attempt to reserve additional instances – but unpredictable inter-instance latency, makes distributing AI work difficult, and achieving high performance across multiple instances challenging .  **Our Solution**  The Cerebras AI Model Studio makes training large Transformer models fast, easy, and affordable. With Cerebras, you have millions of cores, predictable performance, no parallel distribution headaches – all of this enables you to quickly and easily run existing models",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 7,
            "chunk_id": "5c492910-5eaa-491b-8c71-04022e2c8abc",
            "embedding_model": "text-embedding-3-large",
            "text": "less time, you can attempt to reserve additional instances – but unpredictable inter-instance latency, makes distributing AI work difficult, and achieving high performance across multiple instances challenging .  **Our Solution**  The Cerebras AI Model Studio makes training large Transformer models fast, easy, and affordable. With Cerebras, you have millions of cores, predictable performance, no parallel distribution headaches – all of this enables you to quickly and easily run existing models"
        }
    },
    {
        "chunk_id": "d5293e95-c12d-43fd-8143-4bb830c3206f",
        "text": "you to quickly and easily run existing models on your data or to build new models from scratch optimized for your business.  A dedicated cloud-based cluster powered by Cerebras CS-2 systems with millions of AI cores for large language models and generative AI:    - ​ Train 1-175 billion parameter models quickly and easily    - ​ No parallel distribution pain: single-keystroke scaling over millions of cores    - ​ Zero DevOps or firewall pain: simply SSH in and go    - ​ Push-button performance:",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 7,
            "chunk_id": "d5293e95-c12d-43fd-8143-4bb830c3206f",
            "embedding_model": "text-embedding-3-large",
            "text": "you to quickly and easily run existing models on your data or to build new models from scratch optimized for your business.  A dedicated cloud-based cluster powered by Cerebras CS-2 systems with millions of AI cores for large language models and generative AI:    - ​ Train 1-175 billion parameter models quickly and easily    - ​ No parallel distribution pain: single-keystroke scaling over millions of cores    - ​ Zero DevOps or firewall pain: simply SSH in and go    - ​ Push-button performance:"
        }
    },
    {
        "chunk_id": "5bf639fc-251a-49b7-ad62-eceb225e6bff",
        "text": "SSH in and go    - ​ Push-button performance: models in standard PyTorch or TensorFlow    - ​ Flexibility: pre-train or fine-tune models with your data    - ​ Train in a known amount of time, for a fixed fee  **Discover the Benefits of the Cerebras AI Model Studio**   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 7,
            "chunk_id": "5bf639fc-251a-49b7-ad62-eceb225e6bff",
            "embedding_model": "text-embedding-3-large",
            "text": "SSH in and go    - ​ Push-button performance: models in standard PyTorch or TensorFlow    - ​ Flexibility: pre-train or fine-tune models with your data    - ​ Train in a known amount of time, for a fixed fee  **Discover the Benefits of the Cerebras AI Model Studio**   -----"
        }
    },
    {
        "chunk_id": "3b9d9773-1d20-4413-aef8-6bcf120299c7",
        "text": "**Train Large Models in Less Time**    - ​ Train 1–175 billion parameter models 8x faster than the largest publicly available AWS  GPU instance    - ​ Enable higher performing models with our longer sequence lengths (up to 50,000!)  **Ease of Use**    - ​ Easy access: simply SSH in and go    - ​ Simple programming: range of large language models in standard PyTorch and  TensorFlow    - ​ Push-button performance: the power of millions of AI cores dedicated to your work with  no distributed",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 8,
            "chunk_id": "3b9d9773-1d20-4413-aef8-6bcf120299c7",
            "embedding_model": "text-embedding-3-large",
            "text": "**Train Large Models in Less Time**    - ​ Train 1–175 billion parameter models 8x faster than the largest publicly available AWS  GPU instance    - ​ Enable higher performing models with our longer sequence lengths (up to 50,000!)  **Ease of Use**    - ​ Easy access: simply SSH in and go    - ​ Simple programming: range of large language models in standard PyTorch and  TensorFlow    - ​ Push-button performance: the power of millions of AI cores dedicated to your work with  no distributed"
        }
    },
    {
        "chunk_id": "37636009-00f4-4594-87a3-8d50506adcae",
        "text": "cores dedicated to your work with  no distributed programming required    - ​ Even the largest GPT models run without a single minute spent on parallelizing work  **Price**    - ​ Models trained at half the price of AWS    - ​ Predictable fixed price cost for production model training  **Flexibility**    - ​ Train your models from scratch or fine-tune open-source models with your data  **Ownership**    - ​ Dependency free – keep the trained weights for the models you build  **Simple & Secure",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 8,
            "chunk_id": "37636009-00f4-4594-87a3-8d50506adcae",
            "embedding_model": "text-embedding-3-large",
            "text": "cores dedicated to your work with  no distributed programming required    - ​ Even the largest GPT models run without a single minute spent on parallelizing work  **Price**    - ​ Models trained at half the price of AWS    - ​ Predictable fixed price cost for production model training  **Flexibility**    - ​ Train your models from scratch or fine-tune open-source models with your data  **Ownership**    - ​ Dependency free – keep the trained weights for the models you build  **Simple & Secure"
        }
    },
    {
        "chunk_id": "0ae5433d-dde6-495c-80d7-111714ccef7b",
        "text": "for the models you build  **Simple & Secure Cloud Operations**    - ​ Simple onboarding: no DevOps required    - ​ Software environment, libraries, secure storage, networking configured and ready to go  **Should You Fine-Tune or Train from Scratch?**  Ultimately the decision to fine-tune a pre-trained model or to train a model from scratch depends on various factors such as the size of the dataset, the similarity between the pre-trained model's task and the new task, the availability of",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 8,
            "chunk_id": "0ae5433d-dde6-495c-80d7-111714ccef7b",
            "embedding_model": "text-embedding-3-large",
            "text": "for the models you build  **Simple & Secure Cloud Operations**    - ​ Simple onboarding: no DevOps required    - ​ Software environment, libraries, secure storage, networking configured and ready to go  **Should You Fine-Tune or Train from Scratch?**  Ultimately the decision to fine-tune a pre-trained model or to train a model from scratch depends on various factors such as the size of the dataset, the similarity between the pre-trained model's task and the new task, the availability of"
        }
    },
    {
        "chunk_id": "fe34e2c8-0bcd-4c18-9aaf-7f19c654b38a",
        "text": "task and the new task, the availability of necessary computational resources (we got you covered there), and overall time constraints. To make it as easy as possible, Cerebras developed the flow chart to the right to help guide you.  If you have a small dataset, fine-tuning a pre-trained model can be a good option. In fine-tuning, you take a pre-trained model and retrain it on a new dataset specific to your task. This approach can save you time since the pre-trained model has already learned",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 8,
            "chunk_id": "fe34e2c8-0bcd-4c18-9aaf-7f19c654b38a",
            "embedding_model": "text-embedding-3-large",
            "text": "task and the new task, the availability of necessary computational resources (we got you covered there), and overall time constraints. To make it as easy as possible, Cerebras developed the flow chart to the right to help guide you.  If you have a small dataset, fine-tuning a pre-trained model can be a good option. In fine-tuning, you take a pre-trained model and retrain it on a new dataset specific to your task. This approach can save you time since the pre-trained model has already learned"
        }
    },
    {
        "chunk_id": "7865753d-f5db-4d01-89f3-30270474b0bf",
        "text": "since the pre-trained model has already learned general features from a large dataset. Fine-tuning can also help to avoid overfitting on small datasets.  However, if you have a large dataset, training a model from scratch may be a better option. Training a model from scratch allows you to have more control over the architecture, hyperparameters, and optimization strategy, which can lead to better performance on the   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 8,
            "chunk_id": "7865753d-f5db-4d01-89f3-30270474b0bf",
            "embedding_model": "text-embedding-3-large",
            "text": "since the pre-trained model has already learned general features from a large dataset. Fine-tuning can also help to avoid overfitting on small datasets.  However, if you have a large dataset, training a model from scratch may be a better option. Training a model from scratch allows you to have more control over the architecture, hyperparameters, and optimization strategy, which can lead to better performance on the   -----"
        }
    },
    {
        "chunk_id": "aaca133b-5226-43ea-af70-675a7a5a059b",
        "text": "specific task. Additionally, if the pre-trained model's task is significantly different from your task, fine-tuning may not be as effective.  **Fine-Tuning**  **Standard Offering** The Fine-Tuning Standard Offering is a self-service process, similar to the Training from Scratch Standard Offering. Pricing is based per 1,000 tokens so there's no surprises. Minimum spend is $10,000.  **White-Glove Support with Cerebras Experts** With White-Glove Support, Cerebras thought leaders will fine-tune a",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 9,
            "chunk_id": "aaca133b-5226-43ea-af70-675a7a5a059b",
            "embedding_model": "text-embedding-3-large",
            "text": "specific task. Additionally, if the pre-trained model's task is significantly different from your task, fine-tuning may not be as effective.  **Fine-Tuning**  **Standard Offering** The Fine-Tuning Standard Offering is a self-service process, similar to the Training from Scratch Standard Offering. Pricing is based per 1,000 tokens so there's no surprises. Minimum spend is $10,000.  **White-Glove Support with Cerebras Experts** With White-Glove Support, Cerebras thought leaders will fine-tune a"
        }
    },
    {
        "chunk_id": "868ff663-0af1-41d0-b6e2-96ea4c3a32cd",
        "text": "Cerebras thought leaders will fine-tune a model on the Cerebras Wafer-Scale Cluster on your behalf and will deliver you trained weights. Contact us directly for pricing.  **Train From Scratch**  Train your own state-of-the-art GPT model for your application on your data. The process is simple:    - ​ Pick a large model from the list below (or contact us for custom projects)    - ​ See the price, time to train: no surprises        - ​ SSH in and get going        - ​ Enjoy secure, dedicated",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 9,
            "chunk_id": "868ff663-0af1-41d0-b6e2-96ea4c3a32cd",
            "embedding_model": "text-embedding-3-large",
            "text": "Cerebras thought leaders will fine-tune a model on the Cerebras Wafer-Scale Cluster on your behalf and will deliver you trained weights. Contact us directly for pricing.  **Train From Scratch**  Train your own state-of-the-art GPT model for your application on your data. The process is simple:    - ​ Pick a large model from the list below (or contact us for custom projects)    - ​ See the price, time to train: no surprises        - ​ SSH in and get going        - ​ Enjoy secure, dedicated"
        }
    },
    {
        "chunk_id": "1de34a20-324b-419f-9f93-a8aed68a6a69",
        "text": "and get going        - ​ Enjoy secure, dedicated access to programming environment for the training  period       - ​ Cerebras model implementation for the chosen model appear        - ​ Systems, code examples, documentation are at your fingertips        - ​ Scripts allow the user to vary training parameters, e.g. batch, learning rate,  training steps, checkpointing frequency        - ​ Use Cerebras-curated Pile dataset to train upon, if desired    - ​ Save and export trained weights and",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 9,
            "chunk_id": "1de34a20-324b-419f-9f93-a8aed68a6a69",
            "embedding_model": "text-embedding-3-large",
            "text": "and get going        - ​ Enjoy secure, dedicated access to programming environment for the training  period       - ​ Cerebras model implementation for the chosen model appear        - ​ Systems, code examples, documentation are at your fingertips        - ​ Scripts allow the user to vary training parameters, e.g. batch, learning rate,  training steps, checkpointing frequency        - ​ Use Cerebras-curated Pile dataset to train upon, if desired    - ​ Save and export trained weights and"
        }
    },
    {
        "chunk_id": "5e9799c0-fe07-4ce4-892c-3813aa6fecc8",
        "text": "- ​ Save and export trained weights and training log data from your work to use as you see  fit  **Additional Services Available**  Cirrascale and Cerebras provides additional services as needed, such as:    - ​ Bigger dedicated clusters to are available to reduce time to accuracy and work on larger  models    - ​ Additional cluster time for hyperparameter tuning, pre-production training runs,  post-production continuous pre-training or fine-tuning is available by the hour    - ​ CPU hours",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 9,
            "chunk_id": "5e9799c0-fe07-4ce4-892c-3813aa6fecc8",
            "embedding_model": "text-embedding-3-large",
            "text": "- ​ Save and export trained weights and training log data from your work to use as you see  fit  **Additional Services Available**  Cirrascale and Cerebras provides additional services as needed, such as:    - ​ Bigger dedicated clusters to are available to reduce time to accuracy and work on larger  models    - ​ Additional cluster time for hyperparameter tuning, pre-production training runs,  post-production continuous pre-training or fine-tuning is available by the hour    - ​ CPU hours"
        }
    },
    {
        "chunk_id": "a9511bbc-c5cf-45eb-bb8b-efe4875d1855",
        "text": "is available by the hour    - ​ CPU hours from Cirrascale for dataset preparation    - ​ CPU or GPU support from Cirrascale for production model inference   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 9,
            "chunk_id": "a9511bbc-c5cf-45eb-bb8b-efe4875d1855",
            "embedding_model": "text-embedding-3-large",
            "text": "is available by the hour    - ​ CPU hours from Cirrascale for dataset preparation    - ​ CPU or GPU support from Cirrascale for production model inference   -----"
        }
    },
    {
        "chunk_id": "398920e5-1866-4f18-aace-272d99a7d720",
        "text": "## **NVIDIA GPU Cloud **  Unmatched End-to-End Accelerated Computing Platform  NVIDIA AI acceleration devices, hosted by Cirrascale, provide multiple GPUs with extremely fast interconnections and a fully accelerated software stack, creating the most optimal platform for HPC and AI training, tuning and inference.  **Expand Horizons with NVIDIA in the Cloud**  **Purpose-Built for AI and HPC** AI, complex simulations, and massive datasets require multiple GPUs with extremely fast interconnections",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 11,
            "chunk_id": "398920e5-1866-4f18-aace-272d99a7d720",
            "embedding_model": "text-embedding-3-large",
            "text": "## **NVIDIA GPU Cloud **  Unmatched End-to-End Accelerated Computing Platform  NVIDIA AI acceleration devices, hosted by Cirrascale, provide multiple GPUs with extremely fast interconnections and a fully accelerated software stack, creating the most optimal platform for HPC and AI training, tuning and inference.  **Expand Horizons with NVIDIA in the Cloud**  **Purpose-Built for AI and HPC** AI, complex simulations, and massive datasets require multiple GPUs with extremely fast interconnections"
        }
    },
    {
        "chunk_id": "d3c708f4-105d-43ea-bff4-872148302d6c",
        "text": "GPUs with extremely fast interconnections and a fully accelerated software stack. The NVIDIA HGX™ AI supercomputing platform brings together the full power of NVIDIA GPUs, NVIDIA NVLink™, NVIDIA networking, and fully optimized AI and high-performance computing (HPC) software stacks to provide the highest application performance and drive the fastest time to insights.  This fully connected topology from NVSwitch enables any GPU to talk to any other GPU concurrently. Notably, this communication",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 11,
            "chunk_id": "d3c708f4-105d-43ea-bff4-872148302d6c",
            "embedding_model": "text-embedding-3-large",
            "text": "GPUs with extremely fast interconnections and a fully accelerated software stack. The NVIDIA HGX™ AI supercomputing platform brings together the full power of NVIDIA GPUs, NVIDIA NVLink™, NVIDIA networking, and fully optimized AI and high-performance computing (HPC) software stacks to provide the highest application performance and drive the fastest time to insights.  This fully connected topology from NVSwitch enables any GPU to talk to any other GPU concurrently. Notably, this communication"
        }
    },
    {
        "chunk_id": "0dc876bb-857e-4abc-af74-2238746f41c2",
        "text": "GPU concurrently. Notably, this communication runs at the NVLink bidirectional speed of 900 gigabytes per second (GB/s), which is more than 14x the bandwidth of the current PCIe Gen4 x16 bus. ​ ​ **Accelerating HGX With NVIDIA Networking** The data center is the new unit of computing, and networking plays an integral role in scaling application performance across it. Paired with NVIDIA Quantum InfiniBand, HGX delivers world-class performance and efficiency, which ensures the full utilization of",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 11,
            "chunk_id": "0dc876bb-857e-4abc-af74-2238746f41c2",
            "embedding_model": "text-embedding-3-large",
            "text": "GPU concurrently. Notably, this communication runs at the NVLink bidirectional speed of 900 gigabytes per second (GB/s), which is more than 14x the bandwidth of the current PCIe Gen4 x16 bus. ​ ​ **Accelerating HGX With NVIDIA Networking** The data center is the new unit of computing, and networking plays an integral role in scaling application performance across it. Paired with NVIDIA Quantum InfiniBand, HGX delivers world-class performance and efficiency, which ensures the full utilization of"
        }
    },
    {
        "chunk_id": "096a7fb4-7f30-4ed7-8349-988e8984066c",
        "text": "efficiency, which ensures the full utilization of computing  resources.  At Cirrascale, our NVIDIA HGX B200 and H200 clusters are built using NVIDIA InfiniBand NDR networking so you receive the most performant cluster for your training and inference needs. Our infrastructure is setup to be optimized for your specific configuration to make sure your training experiments maximize your compute per dollar. ​ ​ **Discover the Benefits of NVIDIA AI Hosted by Cirrascale**  **Flexibility for Training,",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 11,
            "chunk_id": "096a7fb4-7f30-4ed7-8349-988e8984066c",
            "embedding_model": "text-embedding-3-large",
            "text": "efficiency, which ensures the full utilization of computing  resources.  At Cirrascale, our NVIDIA HGX B200 and H200 clusters are built using NVIDIA InfiniBand NDR networking so you receive the most performant cluster for your training and inference needs. Our infrastructure is setup to be optimized for your specific configuration to make sure your training experiments maximize your compute per dollar. ​ ​ **Discover the Benefits of NVIDIA AI Hosted by Cirrascale**  **Flexibility for Training,"
        }
    },
    {
        "chunk_id": "97c599af-21bf-4494-af90-dc9a75216c08",
        "text": "by Cirrascale**  **Flexibility for Training, Fine Tuning, and Inference**    - ​ Supports model development and tuning    - ​ Provides tuned performance for all leading AI models    - ​ The most recognized platform for developing and deploying AI and HPC solutions  **Ease of Use**    - ​ Direct support for leading frameworks    - ​ The reference platform for model libraries such as Hugging Face, enabling easy model  deployment and use   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 11,
            "chunk_id": "97c599af-21bf-4494-af90-dc9a75216c08",
            "embedding_model": "text-embedding-3-large",
            "text": "by Cirrascale**  **Flexibility for Training, Fine Tuning, and Inference**    - ​ Supports model development and tuning    - ​ Provides tuned performance for all leading AI models    - ​ The most recognized platform for developing and deploying AI and HPC solutions  **Ease of Use**    - ​ Direct support for leading frameworks    - ​ The reference platform for model libraries such as Hugging Face, enabling easy model  deployment and use   -----"
        }
    },
    {
        "chunk_id": "66869301-69fa-468d-ab74-a50cf7fb3905",
        "text": "**Extensive Software Support**    - ​ Native CUDA support for the most extensive compatibility with existing compute GPU  software, frameworks and tools    - ​ Predictable pricing model deployed on Cirrascale  **Simple & Secure Cloud Operations**    - ​ Simple onboarding – No DevOps required    - ​ SDKs, storage and network pre-configured and ready to go  **Popular NVIDIA Offerings on the Cirrascale AI Innovation Cloud**  **NVIDIA HGX B200: The New Era of Accelerated Computing is Here** The",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 12,
            "chunk_id": "66869301-69fa-468d-ab74-a50cf7fb3905",
            "embedding_model": "text-embedding-3-large",
            "text": "**Extensive Software Support**    - ​ Native CUDA support for the most extensive compatibility with existing compute GPU  software, frameworks and tools    - ​ Predictable pricing model deployed on Cirrascale  **Simple & Secure Cloud Operations**    - ​ Simple onboarding – No DevOps required    - ​ SDKs, storage and network pre-configured and ready to go  **Popular NVIDIA Offerings on the Cirrascale AI Innovation Cloud**  **NVIDIA HGX B200: The New Era of Accelerated Computing is Here** The"
        }
    },
    {
        "chunk_id": "43a7d071-568b-4b47-936d-3972cd4613a8",
        "text": "New Era of Accelerated Computing is Here** The NVIDIA Blackwell architecture introduces groundbreaking advancements for generative AI and accelerated computing. The incorporation of the second generation Transformer Engine, alongside the faster and wider NVIDIA NVLink interconnect, propels the data center into a new era, with orders of magnitude more performance compared to the previous architecture generation.  Cirrascale offers the HGX B200 in its AI Innovation Cloud as an 8-GPU configuration",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 12,
            "chunk_id": "43a7d071-568b-4b47-936d-3972cd4613a8",
            "embedding_model": "text-embedding-3-large",
            "text": "New Era of Accelerated Computing is Here** The NVIDIA Blackwell architecture introduces groundbreaking advancements for generative AI and accelerated computing. The incorporation of the second generation Transformer Engine, alongside the faster and wider NVIDIA NVLink interconnect, propels the data center into a new era, with orders of magnitude more performance compared to the previous architecture generation.  Cirrascale offers the HGX B200 in its AI Innovation Cloud as an 8-GPU configuration"
        }
    },
    {
        "chunk_id": "1610864d-7236-4173-a53c-3f73c505e4c4",
        "text": "its AI Innovation Cloud as an 8-GPU configuration giving you full GPU-to-GPU bandwidth through NVIDIA NVLink™ Switch. As a premier accelerated scaleup x86 platform with up to 15X faster real-time inference performance, 12X lower cost, and 12X less energy use, HGX B200 is designed for the most demanding AI, data analytics, and high-performance computing (HPC) workloads. ​ ​ **NVIDIA HGX H200: The World’s Leading AI Computing Platform** As workloads explode in complexity, there’s a need for",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 12,
            "chunk_id": "1610864d-7236-4173-a53c-3f73c505e4c4",
            "embedding_model": "text-embedding-3-large",
            "text": "its AI Innovation Cloud as an 8-GPU configuration giving you full GPU-to-GPU bandwidth through NVIDIA NVLink™ Switch. As a premier accelerated scaleup x86 platform with up to 15X faster real-time inference performance, 12X lower cost, and 12X less energy use, HGX B200 is designed for the most demanding AI, data analytics, and high-performance computing (HPC) workloads. ​ ​ **NVIDIA HGX H200: The World’s Leading AI Computing Platform** As workloads explode in complexity, there’s a need for"
        }
    },
    {
        "chunk_id": "b411d699-e61e-402b-832a-ca2972c0b90d",
        "text": "explode in complexity, there’s a need for multiple GPUs to work together with extremely fast communication between them. NVIDIA HGX H200 combines multiple H200 GPUs with a high-speed interconnect powered by NVIDIA NVLink and NVSwitch™ to enable the creation of the world’s most powerful scale-up servers.  Cirrascale offers the HGX H200 as a dedicated, bare-metal offering in an eight H200 GPU configuration. The eight-GPU configuration offers full GPU-to-GPU bandwidth through NVIDIA NVSwitch.",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 12,
            "chunk_id": "b411d699-e61e-402b-832a-ca2972c0b90d",
            "embedding_model": "text-embedding-3-large",
            "text": "explode in complexity, there’s a need for multiple GPUs to work together with extremely fast communication between them. NVIDIA HGX H200 combines multiple H200 GPUs with a high-speed interconnect powered by NVIDIA NVLink and NVSwitch™ to enable the creation of the world’s most powerful scale-up servers.  Cirrascale offers the HGX H200 as a dedicated, bare-metal offering in an eight H200 GPU configuration. The eight-GPU configuration offers full GPU-to-GPU bandwidth through NVIDIA NVSwitch."
        }
    },
    {
        "chunk_id": "918934a9-7866-4823-8ba3-de251ebb22ac",
        "text": "GPU-to-GPU bandwidth through NVIDIA NVSwitch. Leveraging the power of H200 multi-precision Tensor Cores, an eight-way HGX H200 provides over 32 petaFLOPS of FP8 deep learning compute and over 1.1TB of aggregate HBM memory for the highest performance in generative AI and HPC applications.  HGX H200 enables standardized servers that provide the highest performance on various application workloads, including LLM training and inference for the largest models beyond 175 billion parameters, while",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 12,
            "chunk_id": "918934a9-7866-4823-8ba3-de251ebb22ac",
            "embedding_model": "text-embedding-3-large",
            "text": "GPU-to-GPU bandwidth through NVIDIA NVSwitch. Leveraging the power of H200 multi-precision Tensor Cores, an eight-way HGX H200 provides over 32 petaFLOPS of FP8 deep learning compute and over 1.1TB of aggregate HBM memory for the highest performance in generative AI and HPC applications.  HGX H200 enables standardized servers that provide the highest performance on various application workloads, including LLM training and inference for the largest models beyond 175 billion parameters, while"
        }
    },
    {
        "chunk_id": "5e6a411a-b234-4689-bf79-c8d3d035aa4e",
        "text": "models beyond 175 billion parameters, while accelerating time to market for NVIDIA’s ecosystem of partner server  makers.  **NVIDIA HGX H100 in the Cloud with Cirrascale Cloud Services**   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 12,
            "chunk_id": "5e6a411a-b234-4689-bf79-c8d3d035aa4e",
            "embedding_model": "text-embedding-3-large",
            "text": "models beyond 175 billion parameters, while accelerating time to market for NVIDIA’s ecosystem of partner server  makers.  **NVIDIA HGX H100 in the Cloud with Cirrascale Cloud Services**   -----"
        }
    },
    {
        "chunk_id": "2920230b-7afb-4b07-89de-105f80a6645a",
        "text": "The NVIDIA HGX H100 brings together the full power of NVIDIA H100 Tensor Core GPUs, NVIDIA® NVLink®, NVSwitch technology, and NVIDIA Quantum-2 InfiniBand networking. As a specialized cloud services provider, Cirrascale delivers all of this to you via the cloud. We offer fully-managed NVIDIA GPU-based clusters at a fraction of the cost of traditional cloud service providers. These bare-metal servers are completely dedicated to you with no contention and no performance issues due to virtualization",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 13,
            "chunk_id": "2920230b-7afb-4b07-89de-105f80a6645a",
            "embedding_model": "text-embedding-3-large",
            "text": "The NVIDIA HGX H100 brings together the full power of NVIDIA H100 Tensor Core GPUs, NVIDIA® NVLink®, NVSwitch technology, and NVIDIA Quantum-2 InfiniBand networking. As a specialized cloud services provider, Cirrascale delivers all of this to you via the cloud. We offer fully-managed NVIDIA GPU-based clusters at a fraction of the cost of traditional cloud service providers. These bare-metal servers are completely dedicated to you with no contention and no performance issues due to virtualization"
        }
    },
    {
        "chunk_id": "aa7441ed-e353-4123-8306-9bdbacf424d2",
        "text": "and no performance issues due to virtualization overhead.  Our flat-rate, no surprises billing model means we can provide you with a price that is up to 30% lower than the other cloud service providers. We also don't nickel-and-dime you by charging to get your data in to or out of our cloud. Instead, we charge no ingress or egress fees, so you never receive a supplemental bill.   -----",
        "metadata": {
            "parent_document_id": "AI Innovation Cloud.pdf",
            "parent_content_hash": "3f08aedf5c4c799528933b82bc11a35044fa77f173c2fbbf4ba83e089dd620b6",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/AI Innovation Cloud.pdf",
            "page_number": 13,
            "chunk_id": "aa7441ed-e353-4123-8306-9bdbacf424d2",
            "embedding_model": "text-embedding-3-large",
            "text": "and no performance issues due to virtualization overhead.  Our flat-rate, no surprises billing model means we can provide you with a price that is up to 30% lower than the other cloud service providers. We also don't nickel-and-dime you by charging to get your data in to or out of our cloud. Instead, we charge no ingress or egress fees, so you never receive a supplemental bill.   -----"
        }
    },
    {
        "chunk_id": "51603c89-3ba2-4ca8-a9ac-39596d14c672",
        "text": "# Cirrascale Inference Platform #### A New Era of Smarter Inferencing for Enterprise  ## *Analyze models, deploy on optimal * *accelerators, and balance workloads * *across regions automatically* ### Go Beyond Traditional Hyperscalers  Your AI journey may have begun with hyperscaler AI services  to evaluate models, test specific use-cases and start initial  deployments. As you move to full-scale deployment, you  need predictable costs, resource control, and experienced AI  services tailored to",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "51603c89-3ba2-4ca8-a9ac-39596d14c672",
            "embedding_model": "text-embedding-3-large",
            "text": "# Cirrascale Inference Platform #### A New Era of Smarter Inferencing for Enterprise  ## *Analyze models, deploy on optimal * *accelerators, and balance workloads * *across regions automatically* ### Go Beyond Traditional Hyperscalers  Your AI journey may have begun with hyperscaler AI services  to evaluate models, test specific use-cases and start initial  deployments. As you move to full-scale deployment, you  need predictable costs, resource control, and experienced AI  services tailored to"
        }
    },
    {
        "chunk_id": "e8593aba-46f5-4053-9c36-c294f1a038d2",
        "text": "control, and experienced AI  services tailored to your requirements. Cirrascale’s Inference  Platform enables you to scale up beyond the limitations of  hyperscalers with key enterprise-ready features.  ### Burns Through Workloads, Not Your Budget  The Cirrascale Inference Platform is designed to allow for  easier deployment, use, and scale-up of Generative AI models,  including Large Language Models (LLM’s), image, audio, and  video models. The platform provisions AI model pipelines  that can",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "e8593aba-46f5-4053-9c36-c294f1a038d2",
            "embedding_model": "text-embedding-3-large",
            "text": "control, and experienced AI  services tailored to your requirements. Cirrascale’s Inference  Platform enables you to scale up beyond the limitations of  hyperscalers with key enterprise-ready features.  ### Burns Through Workloads, Not Your Budget  The Cirrascale Inference Platform is designed to allow for  easier deployment, use, and scale-up of Generative AI models,  including Large Language Models (LLM’s), image, audio, and  video models. The platform provisions AI model pipelines  that can"
        }
    },
    {
        "chunk_id": "c0f3d8f2-c25e-4087-bb40-bc74e39a6a71",
        "text": "platform provisions AI model pipelines  that can be used with existing enterprise, SaaS or proprietary  workflows that may be run on-premises or with a hyperscaler.  Additionally, it dynamically balances workloads across regions,  helping to smooth out peak demands, enhance operational  efficiencies, and reduce costs. ### Platform Features  ### Agile and Scaleable Performance  A key advantage of the platform is its ability to deploy your  own tuned or customized models based on token",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "c0f3d8f2-c25e-4087-bb40-bc74e39a6a71",
            "embedding_model": "text-embedding-3-large",
            "text": "platform provisions AI model pipelines  that can be used with existing enterprise, SaaS or proprietary  workflows that may be run on-premises or with a hyperscaler.  Additionally, it dynamically balances workloads across regions,  helping to smooth out peak demands, enhance operational  efficiencies, and reduce costs. ### Platform Features  ### Agile and Scaleable Performance  A key advantage of the platform is its ability to deploy your  own tuned or customized models based on token"
        }
    },
    {
        "chunk_id": "8fa48151-7278-4482-8f18-fe2ebfa65c88",
        "text": "own tuned or customized models based on token performance  needs and user demand. Cirrascale’s Inference Platform  intelligently selects the most ideal AI accelerators to balance  cost and performance for any given AI inference workflow. Our  model pipelines dynamically scale the necessary resources  to maintain required token throughput and time-to-answer,  ensuring seamless support for both low-latency, real-time  applications and batch processing workloads.    - Premiering with NVIDIA",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "8fa48151-7278-4482-8f18-fe2ebfa65c88",
            "embedding_model": "text-embedding-3-large",
            "text": "own tuned or customized models based on token performance  needs and user demand. Cirrascale’s Inference Platform  intelligently selects the most ideal AI accelerators to balance  cost and performance for any given AI inference workflow. Our  model pipelines dynamically scale the necessary resources  to maintain required token throughput and time-to-answer,  ensuring seamless support for both low-latency, real-time  applications and batch processing workloads.    - Premiering with NVIDIA"
        }
    },
    {
        "chunk_id": "546756c8-668a-4863-a0f2-e5ed0d3c47ac",
        "text": "processing workloads.    - Premiering with NVIDIA Blackwell B200, RTX PRO 6000 Blackwell Server Edition, and Hopper H100 and H200 GPUs.  - Dynamically balances workloads across regions so you don’t have to.  - Serverless deployments that provide an instant AI Model Pipeline.  - Pre-compiled foundational models optimized for underlying accelerators (such as Llama 3.3 Instruct and Deepseek R1).  - Web console-based deployment and configuration – no SSH access required, includes monitoring tools",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "546756c8-668a-4863-a0f2-e5ed0d3c47ac",
            "embedding_model": "text-embedding-3-large",
            "text": "processing workloads.    - Premiering with NVIDIA Blackwell B200, RTX PRO 6000 Blackwell Server Edition, and Hopper H100 and H200 GPUs.  - Dynamically balances workloads across regions so you don’t have to.  - Serverless deployments that provide an instant AI Model Pipeline.  - Pre-compiled foundational models optimized for underlying accelerators (such as Llama 3.3 Instruct and Deepseek R1).  - Web console-based deployment and configuration – no SSH access required, includes monitoring tools"
        }
    },
    {
        "chunk_id": "59a08baf-75b2-4e09-ac24-0b32e7c34673",
        "text": "no SSH access required, includes monitoring tools for throughput and  performance analysis.  - API Access to the AI model utilizing OpenAI API’s and other common interfaces via public access endpoints.  - Supports fine-tuned models, allowing for custom weights or parameters to be applied on an AI model pipeline.  - Priced by token volume for the given AI Model used in the pipeline. ### Optional Features  - Customized weights, tuning, and Retrieval-Augmented-Generation (RAG) capabilities for an",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "59a08baf-75b2-4e09-ac24-0b32e7c34673",
            "embedding_model": "text-embedding-3-large",
            "text": "no SSH access required, includes monitoring tools for throughput and  performance analysis.  - API Access to the AI model utilizing OpenAI API’s and other common interfaces via public access endpoints.  - Supports fine-tuned models, allowing for custom weights or parameters to be applied on an AI model pipeline.  - Priced by token volume for the given AI Model used in the pipeline. ### Optional Features  - Customized weights, tuning, and Retrieval-Augmented-Generation (RAG) capabilities for an"
        }
    },
    {
        "chunk_id": "cd0ff86f-2675-4538-9562-fe4b06d8040b",
        "text": "(RAG) capabilities for an AI Model Pipeline.  - Interconnect of the AI model pipeline to an on-premises or hyperscaler environment to run directly aside existing workflows.  - Proprietary model support.  - Reserved capacity for time-based burst requirements.  Cirrascale Cloud Services 5775 Kearny Villa Road, San Diego, CA 92123 USA  Phone 888-942-3800  Web www.cirrascale.com   ©2025, Cirrascale Cloud Services. All Rights Reserved. Cirrascale and the Cirrascale logo are registered trademarks of",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "cd0ff86f-2675-4538-9562-fe4b06d8040b",
            "embedding_model": "text-embedding-3-large",
            "text": "(RAG) capabilities for an AI Model Pipeline.  - Interconnect of the AI model pipeline to an on-premises or hyperscaler environment to run directly aside existing workflows.  - Proprietary model support.  - Reserved capacity for time-based burst requirements.  Cirrascale Cloud Services 5775 Kearny Villa Road, San Diego, CA 92123 USA  Phone 888-942-3800  Web www.cirrascale.com   ©2025, Cirrascale Cloud Services. All Rights Reserved. Cirrascale and the Cirrascale logo are registered trademarks of"
        }
    },
    {
        "chunk_id": "6e2f9ea2-fcec-4ffc-98e0-e618aff61a98",
        "text": "the Cirrascale logo are registered trademarks of Cirrascale Cloud Services. NVIDIA is a trademark or registered trademark of NVIDIA Corporation or its subsidiaries in the United States and other countries. All other names or marks are property of their respective owners. No part of this document may be reproduced without consent from Cirrascale Cloud Services. Technical specifications and pricing subject to change without notice.   CCSIPDS - REV B - 3/2025   -----",
        "metadata": {
            "parent_document_id": "Inference Platform.pdf",
            "parent_content_hash": "ba026dd5cdc1d1354dd525c33d5d6d49fa5dffe4b93ddba87ab5e23ec9ef5074",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Inference Platform.pdf",
            "page_number": 1,
            "chunk_id": "6e2f9ea2-fcec-4ffc-98e0-e618aff61a98",
            "embedding_model": "text-embedding-3-large",
            "text": "the Cirrascale logo are registered trademarks of Cirrascale Cloud Services. NVIDIA is a trademark or registered trademark of NVIDIA Corporation or its subsidiaries in the United States and other countries. All other names or marks are property of their respective owners. No part of this document may be reproduced without consent from Cirrascale Cloud Services. Technical specifications and pricing subject to change without notice.   CCSIPDS - REV B - 3/2025   -----"
        }
    },
    {
        "chunk_id": "48acf882-a50e-4d74-8217-f13bd4c3a3dd",
        "text": "## **Generative AI **  The Cirrascale AI Innovation Cloud is specifically designed to handle Generative AI models so your customers can create breathtaking content.  **Purpose Built for Generative AI Innovation** Cirrascale is at the forefront of cloud innovation, providing a platform purpose-built for generative AI. Designed to meet the unique demands of generative AI models, Cirrascale enables organizations to confidently scale and deploy their AI applications with unmatched efficiency. Our",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 2,
            "chunk_id": "48acf882-a50e-4d74-8217-f13bd4c3a3dd",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Generative AI **  The Cirrascale AI Innovation Cloud is specifically designed to handle Generative AI models so your customers can create breathtaking content.  **Purpose Built for Generative AI Innovation** Cirrascale is at the forefront of cloud innovation, providing a platform purpose-built for generative AI. Designed to meet the unique demands of generative AI models, Cirrascale enables organizations to confidently scale and deploy their AI applications with unmatched efficiency. Our"
        }
    },
    {
        "chunk_id": "909d2722-ffe5-4cd8-b8e7-609d3f39dcad",
        "text": "AI applications with unmatched efficiency. Our infrastructure is tailored to support every phase of your AI journey, from pre-training and training to real-time inference, ensuring that your generative AI solutions are always production ready.  **Optimized Performance for Real-Time AI Modes** Generative AI models require significant computing power and specialized hardware to function effectively. The models used for Generative AI primarily come from foundational models, designed for more",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 2,
            "chunk_id": "909d2722-ffe5-4cd8-b8e7-609d3f39dcad",
            "embedding_model": "text-embedding-3-large",
            "text": "AI applications with unmatched efficiency. Our infrastructure is tailored to support every phase of your AI journey, from pre-training and training to real-time inference, ensuring that your generative AI solutions are always production ready.  **Optimized Performance for Real-Time AI Modes** Generative AI models require significant computing power and specialized hardware to function effectively. The models used for Generative AI primarily come from foundational models, designed for more"
        }
    },
    {
        "chunk_id": "660808b3-bf79-42e4-994d-bc39f16b3dd3",
        "text": "come from foundational models, designed for more general use cases. The most recognized Generative AI models today are Large Language Models (LLMs) that generate text, but models are also designed for generating images and code. These models are pre-trained with extensive data sets to cover more general use cases. These models can however be enhanced for a specific enterprise, industry or use cases by retraining with augmented or synthetic data, tuning with labeled examples to update weights or",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 2,
            "chunk_id": "660808b3-bf79-42e4-994d-bc39f16b3dd3",
            "embedding_model": "text-embedding-3-large",
            "text": "come from foundational models, designed for more general use cases. The most recognized Generative AI models today are Large Language Models (LLMs) that generate text, but models are also designed for generating images and code. These models are pre-trained with extensive data sets to cover more general use cases. These models can however be enhanced for a specific enterprise, industry or use cases by retraining with augmented or synthetic data, tuning with labeled examples to update weights or"
        }
    },
    {
        "chunk_id": "e7291488-4127-43bf-a77a-6e1498158cf9",
        "text": "tuning with labeled examples to update weights or using retrieval-augmented-generation (RAG) in LLMs to utilize authoritative data to improve responses.  **Managed Services and Cost-Effective Scalability** At Cirrascale we understand that managing complex AI infrastructure can be a challenge. That’s why we offer managed services that take the burden off your team, allowing you to focus on innovating with generative AI. Our hands-free approach includes setting up scheduling services, managing",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 2,
            "chunk_id": "e7291488-4127-43bf-a77a-6e1498158cf9",
            "embedding_model": "text-embedding-3-large",
            "text": "tuning with labeled examples to update weights or using retrieval-augmented-generation (RAG) in LLMs to utilize authoritative data to improve responses.  **Managed Services and Cost-Effective Scalability** At Cirrascale we understand that managing complex AI infrastructure can be a challenge. That’s why we offer managed services that take the burden off your team, allowing you to focus on innovating with generative AI. Our hands-free approach includes setting up scheduling services, managing"
        }
    },
    {
        "chunk_id": "e710a85a-537d-4df0-93ed-a8c5cd318646",
        "text": "includes setting up scheduling services, managing user access, and ensuring your infrastructure is secure and optimized. With transparent, flat-rate billing, you can scale your AI efforts without worrying about unexpected costs. Trust Cirrascale to provide the secure, scalable platform your generative AI initiatives need to thrive.. Cirrascale’s AI Innovation Cloud platform is a much better choice for those companies needing cloud-based, dedicated servers for Generative AI. You'll get charged",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 2,
            "chunk_id": "e710a85a-537d-4df0-93ed-a8c5cd318646",
            "embedding_model": "text-embedding-3-large",
            "text": "includes setting up scheduling services, managing user access, and ensuring your infrastructure is secure and optimized. With transparent, flat-rate billing, you can scale your AI efforts without worrying about unexpected costs. Trust Cirrascale to provide the secure, scalable platform your generative AI initiatives need to thrive.. Cirrascale’s AI Innovation Cloud platform is a much better choice for those companies needing cloud-based, dedicated servers for Generative AI. You'll get charged"
        }
    },
    {
        "chunk_id": "98ec967a-88d4-4284-b490-a5b37d3df5e4",
        "text": "servers for Generative AI. You'll get charged one flat rate per month and that's it. No ingress or egress fees, no overage charges, no surprises... and we provide a level of support that goes beyond other providers.   -----",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 2,
            "chunk_id": "98ec967a-88d4-4284-b490-a5b37d3df5e4",
            "embedding_model": "text-embedding-3-large",
            "text": "servers for Generative AI. You'll get charged one flat rate per month and that's it. No ingress or egress fees, no overage charges, no surprises... and we provide a level of support that goes beyond other providers.   -----"
        }
    },
    {
        "chunk_id": "60de3975-302a-44a9-82ff-9ce82a5e22f6",
        "text": "# Autonomous Systems and Robotics   -----",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 3,
            "chunk_id": "60de3975-302a-44a9-82ff-9ce82a5e22f6",
            "embedding_model": "text-embedding-3-large",
            "text": "# Autonomous Systems and Robotics   -----"
        }
    },
    {
        "chunk_id": "f46df3da-455c-4c0d-8fb5-3ce936ec67de",
        "text": "## **Autonomous Systems and Robotics **  Cirrascale can help you identify and eliminate aspects of your autonomous system or robotics workflows that hinder your ability to quickly process collected data for ground-truth generation and system performance improvement.  Autonomous system and robotics developers use various workflows to create their perception, planning, and control models. These workflows typically involve collecting, processing, and storing massive amounts of data so that data",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 4,
            "chunk_id": "f46df3da-455c-4c0d-8fb5-3ce936ec67de",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Autonomous Systems and Robotics **  Cirrascale can help you identify and eliminate aspects of your autonomous system or robotics workflows that hinder your ability to quickly process collected data for ground-truth generation and system performance improvement.  Autonomous system and robotics developers use various workflows to create their perception, planning, and control models. These workflows typically involve collecting, processing, and storing massive amounts of data so that data"
        }
    },
    {
        "chunk_id": "e184aed6-b5e1-4c6d-8187-10a2eee8528f",
        "text": "and storing massive amounts of data so that data scientists can build datasets for training and validating their models. As these workflows are utilized, customers encounter bottlenecks that prevent them from using their resources. These bottlenecks usually manifest as slow data processing, leading to backlogs that force teams to select subsets of data for processing, potentially missing essential edge cases that help improve system performance.  Larger cloud providers excel at one thing:",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 4,
            "chunk_id": "e184aed6-b5e1-4c6d-8187-10a2eee8528f",
            "embedding_model": "text-embedding-3-large",
            "text": "and storing massive amounts of data so that data scientists can build datasets for training and validating their models. As these workflows are utilized, customers encounter bottlenecks that prevent them from using their resources. These bottlenecks usually manifest as slow data processing, leading to backlogs that force teams to select subsets of data for processing, potentially missing essential edge cases that help improve system performance.  Larger cloud providers excel at one thing:"
        }
    },
    {
        "chunk_id": "47a75f76-0fee-4042-91b2-af5949389ae6",
        "text": "Larger cloud providers excel at one thing: hyperscale. However, they struggle to handle the large volumes of data generated by autonomous systems and robotics. Multiple cameras, LiDAR’s, Radars, bus-collected data, and other sensor outputs create massive data challenges if the necessary compute acceleration devices cannot manage the volume of data. A more custom-tailored approach is required to eliminate bottlenecks and achieve the full performance needed to process data in a timely manner.",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 4,
            "chunk_id": "47a75f76-0fee-4042-91b2-af5949389ae6",
            "embedding_model": "text-embedding-3-large",
            "text": "Larger cloud providers excel at one thing: hyperscale. However, they struggle to handle the large volumes of data generated by autonomous systems and robotics. Multiple cameras, LiDAR’s, Radars, bus-collected data, and other sensor outputs create massive data challenges if the necessary compute acceleration devices cannot manage the volume of data. A more custom-tailored approach is required to eliminate bottlenecks and achieve the full performance needed to process data in a timely manner."
        }
    },
    {
        "chunk_id": "d7d8a41d-9cf9-4595-abaf-a60f81ccb2e6",
        "text": "needed to process data in a timely manner. This is where Cirrascale comes in. With in-house expertise in data collection and analysis for autonomous systems and robotics, we understand where the risks lie and how to mitigate them. Additionally, our cloud is structured differently, so you never experience hidden fees. Large providers often squeeze you with extra fees and charges to get your data out of their storage clouds, leading to a sense of lock-in because the cost of extracting data",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 4,
            "chunk_id": "d7d8a41d-9cf9-4595-abaf-a60f81ccb2e6",
            "embedding_model": "text-embedding-3-large",
            "text": "needed to process data in a timely manner. This is where Cirrascale comes in. With in-house expertise in data collection and analysis for autonomous systems and robotics, we understand where the risks lie and how to mitigate them. Additionally, our cloud is structured differently, so you never experience hidden fees. Large providers often squeeze you with extra fees and charges to get your data out of their storage clouds, leading to a sense of lock-in because the cost of extracting data"
        }
    },
    {
        "chunk_id": "1eb6c2a5-9de1-4373-a1f1-e89a2c1df8d8",
        "text": "of lock-in because the cost of extracting data becomes prohibitively expensive. With us, you won’t face that issue, as we don’t charge any ingress or egress fees.   -----",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 4,
            "chunk_id": "1eb6c2a5-9de1-4373-a1f1-e89a2c1df8d8",
            "embedding_model": "text-embedding-3-large",
            "text": "of lock-in because the cost of extracting data becomes prohibitively expensive. With us, you won’t face that issue, as we don’t charge any ingress or egress fees.   -----"
        }
    },
    {
        "chunk_id": "ae287d7f-30c1-4254-b243-1980246bc25c",
        "text": "## **Computer Vision **  Image and Object Classification, Detection, and Tracking  Computers can be trained to accurately identify objects in images and videos faster than ever before, but they need massive amounts of data to do so. Even for pre-trained models, re-training or tuning is essential to ensure high accuracy and effectiveness of a model. What was once possible with on-premises workstations or servers, using initial models with limited pattern matching capabilities, has now shifted to",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 6,
            "chunk_id": "ae287d7f-30c1-4254-b243-1980246bc25c",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Computer Vision **  Image and Object Classification, Detection, and Tracking  Computers can be trained to accurately identify objects in images and videos faster than ever before, but they need massive amounts of data to do so. Even for pre-trained models, re-training or tuning is essential to ensure high accuracy and effectiveness of a model. What was once possible with on-premises workstations or servers, using initial models with limited pattern matching capabilities, has now shifted to"
        }
    },
    {
        "chunk_id": "29c04000-f9ee-4edc-bfb5-b8930eab870f",
        "text": "pattern matching capabilities, has now shifted to deep learning and machine learning models that add AI capabilities, providing a deeper understanding of visual content. As the needs for acceleration of these models increases, companies often attempt to scale their operations for computer vision needs on cloud services such as AWS or GCP, only to realize that prolonged usage of these services can be prohibitively expensive.  With powerful models at their disposal, specific market segments- such",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 6,
            "chunk_id": "29c04000-f9ee-4edc-bfb5-b8930eab870f",
            "embedding_model": "text-embedding-3-large",
            "text": "pattern matching capabilities, has now shifted to deep learning and machine learning models that add AI capabilities, providing a deeper understanding of visual content. As the needs for acceleration of these models increases, companies often attempt to scale their operations for computer vision needs on cloud services such as AWS or GCP, only to realize that prolonged usage of these services can be prohibitively expensive.  With powerful models at their disposal, specific market segments- such"
        }
    },
    {
        "chunk_id": "5de251b2-b7b2-4fea-b987-e364984d44d3",
        "text": "at their disposal, specific market segments- such as autonomous and robotic systems, healthcare, manufacturing, agriculture and security applications- can take data from sensors and other imaging devices and analyze it in a timely manner to meet the needs of specific workflows.  Cirrascale has been leveraging GPUs for computer vision use cases, enabling groundbreaking improvements across image and object classification, detection and tracking applications. Today, with a wider variety of",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 6,
            "chunk_id": "5de251b2-b7b2-4fea-b987-e364984d44d3",
            "embedding_model": "text-embedding-3-large",
            "text": "at their disposal, specific market segments- such as autonomous and robotic systems, healthcare, manufacturing, agriculture and security applications- can take data from sensors and other imaging devices and analyze it in a timely manner to meet the needs of specific workflows.  Cirrascale has been leveraging GPUs for computer vision use cases, enabling groundbreaking improvements across image and object classification, detection and tracking applications. Today, with a wider variety of"
        }
    },
    {
        "chunk_id": "b9c18f3e-1f0c-4635-a980-15111141b3f0",
        "text": "applications. Today, with a wider variety of acceleration options available for computer vision, Cirrascale’s AI Innovation Cloud platform is a superior choice for companies needing cloud-based, dedicated servers. You'll be charged one flat rate per month -no ingress or egress fees, no overage charges, no surprises. Plus, we provide a level of support that goes beyond other providers.   -----",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 6,
            "chunk_id": "b9c18f3e-1f0c-4635-a980-15111141b3f0",
            "embedding_model": "text-embedding-3-large",
            "text": "applications. Today, with a wider variety of acceleration options available for computer vision, Cirrascale’s AI Innovation Cloud platform is a superior choice for companies needing cloud-based, dedicated servers. You'll be charged one flat rate per month -no ingress or egress fees, no overage charges, no surprises. Plus, we provide a level of support that goes beyond other providers.   -----"
        }
    },
    {
        "chunk_id": "e17b0717-b779-42dd-9d6c-feedbf877926",
        "text": "## **High Performance Computing **  **High Performance Computing (HPC) is a cornerstone in driving forward the frontiers of** **scientific discovery and innovation**  From climate modeling to advanced simulations in aerospace and biomedical research, Cirrascale empowers researchers by seamlessly integrating traditional computational methods with the latest advancements in AI, machine learning, big data analytics, and edge computing. Together, we're unlocking the secrets of our world, one",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 8,
            "chunk_id": "e17b0717-b779-42dd-9d6c-feedbf877926",
            "embedding_model": "text-embedding-3-large",
            "text": "## **High Performance Computing **  **High Performance Computing (HPC) is a cornerstone in driving forward the frontiers of** **scientific discovery and innovation**  From climate modeling to advanced simulations in aerospace and biomedical research, Cirrascale empowers researchers by seamlessly integrating traditional computational methods with the latest advancements in AI, machine learning, big data analytics, and edge computing. Together, we're unlocking the secrets of our world, one"
        }
    },
    {
        "chunk_id": "578c85d5-49c8-4cce-9a3d-509c6931020c",
        "text": "we're unlocking the secrets of our world, one calculation at a time.  **Empowering Demanding Workloads** Whether it's complex simulations, the fusion of HPC and AI, or data-intensive visualizations, our HPC solutions are designed to accelerate breakthroughs across diverse industries—from cutting-edge scientific research to intricate financial modeling. Cirrascale’s cloud-based HPC platform, powered by top-tier GPUs, enables professionals to achieve their most ambitious goals and transform their",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 8,
            "chunk_id": "578c85d5-49c8-4cce-9a3d-509c6931020c",
            "embedding_model": "text-embedding-3-large",
            "text": "we're unlocking the secrets of our world, one calculation at a time.  **Empowering Demanding Workloads** Whether it's complex simulations, the fusion of HPC and AI, or data-intensive visualizations, our HPC solutions are designed to accelerate breakthroughs across diverse industries—from cutting-edge scientific research to intricate financial modeling. Cirrascale’s cloud-based HPC platform, powered by top-tier GPUs, enables professionals to achieve their most ambitious goals and transform their"
        }
    },
    {
        "chunk_id": "235c9f62-4132-4ffe-bbe8-7ab9eb7dd899",
        "text": "their most ambitious goals and transform their visions into reality.  With a focus on scalability, reliability, and unmatched performance, Cirrascale’s infrastructure adapts to the evolving needs of your projects. Our dedicated support team and extensive resources ensure that you have the tools and expertise to tackle the most challenging computational tasks. By offering flexible configurations and on-demand resources, we help you optimize costs while maximizing efficiency, enabling you to",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 8,
            "chunk_id": "235c9f62-4132-4ffe-bbe8-7ab9eb7dd899",
            "embedding_model": "text-embedding-3-large",
            "text": "their most ambitious goals and transform their visions into reality.  With a focus on scalability, reliability, and unmatched performance, Cirrascale’s infrastructure adapts to the evolving needs of your projects. Our dedicated support team and extensive resources ensure that you have the tools and expertise to tackle the most challenging computational tasks. By offering flexible configurations and on-demand resources, we help you optimize costs while maximizing efficiency, enabling you to"
        }
    },
    {
        "chunk_id": "ee2b13c4-6f43-425c-893b-84ead4ec3c6f",
        "text": "while maximizing efficiency, enabling you to focus on what truly matters—innovating and pushing the boundaries of what’s possible.  Today, with a wider variety of acceleration options available for high-performance computing, Cirrascale’s AI Innovation Cloud platform is a superior choice for companies needing cloud-based, dedicated servers. You'll be charged one flat rate per month -no ingress or egress fees, no overage charges, no surprises. Plus, we provide a level of support that goes beyond",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 8,
            "chunk_id": "ee2b13c4-6f43-425c-893b-84ead4ec3c6f",
            "embedding_model": "text-embedding-3-large",
            "text": "while maximizing efficiency, enabling you to focus on what truly matters—innovating and pushing the boundaries of what’s possible.  Today, with a wider variety of acceleration options available for high-performance computing, Cirrascale’s AI Innovation Cloud platform is a superior choice for companies needing cloud-based, dedicated servers. You'll be charged one flat rate per month -no ingress or egress fees, no overage charges, no surprises. Plus, we provide a level of support that goes beyond"
        }
    },
    {
        "chunk_id": "4339e4ca-cf5e-4d28-ada9-db81dfad36be",
        "text": "we provide a level of support that goes beyond other providers.   -----",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 8,
            "chunk_id": "4339e4ca-cf5e-4d28-ada9-db81dfad36be",
            "embedding_model": "text-embedding-3-large",
            "text": "we provide a level of support that goes beyond other providers.   -----"
        }
    },
    {
        "chunk_id": "97da133b-cc96-43fb-acc8-a0f8778c2f71",
        "text": "## **Audio Processing **  NLP / Audio Processing  Audio Processing has been used for years to detect, decipher, and understand complex language. Unlike Large Language Models (LLMs), which focus on text input, NLP / Audio Processing applications are literally everywhere in our daily lives, as most communication occurs through spoken language. Whether it’s a simple audio-based search, a digital assistant request, language translation, or more, a vast amount of deep learning models power these",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 10,
            "chunk_id": "97da133b-cc96-43fb-acc8-a0f8778c2f71",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Audio Processing **  NLP / Audio Processing  Audio Processing has been used for years to detect, decipher, and understand complex language. Unlike Large Language Models (LLMs), which focus on text input, NLP / Audio Processing applications are literally everywhere in our daily lives, as most communication occurs through spoken language. Whether it’s a simple audio-based search, a digital assistant request, language translation, or more, a vast amount of deep learning models power these"
        }
    },
    {
        "chunk_id": "23e2a2df-9052-48f5-9a8a-7380637348df",
        "text": "a vast amount of deep learning models power these applications. The resources required to run these models continue to grow, demanding large-scale, multi-GPU servers for processing. Companies often attempt to scale their operations for natural language and audio processing on cloud services such as AWS or GCP, only to find that prolonged usage can be prohibitively expensive.  Cirrascale Cloud Services leverages NVIDIA GPUs for Audio Processing to make groundbreaking improvements across various",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 10,
            "chunk_id": "23e2a2df-9052-48f5-9a8a-7380637348df",
            "embedding_model": "text-embedding-3-large",
            "text": "a vast amount of deep learning models power these applications. The resources required to run these models continue to grow, demanding large-scale, multi-GPU servers for processing. Companies often attempt to scale their operations for natural language and audio processing on cloud services such as AWS or GCP, only to find that prolonged usage can be prohibitively expensive.  Cirrascale Cloud Services leverages NVIDIA GPUs for Audio Processing to make groundbreaking improvements across various"
        }
    },
    {
        "chunk_id": "2c8de7c9-e482-4736-b4cc-fda3f4b58fbc",
        "text": "make groundbreaking improvements across various language and audio applications. Given the immense GPU compute power needed, the Cirrascale Cloud Services innovation cloud is a superior choice for companies needing dedicated, long-term cloud-based servers. You'll be charged one flat rate per month-no ingress or egress fees, no overage charges, no surprises. Plus, we provide a level of support that goes beyond other providers.   -----",
        "metadata": {
            "parent_document_id": "Industry Solutions.pdf",
            "parent_content_hash": "713278ba1091b03991b351f1eb056ea8c8343b85fc113308a94e6b245879d1c2",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/Industry Solutions.pdf",
            "page_number": 10,
            "chunk_id": "2c8de7c9-e482-4736-b4cc-fda3f4b58fbc",
            "embedding_model": "text-embedding-3-large",
            "text": "make groundbreaking improvements across various language and audio applications. Given the immense GPU compute power needed, the Cirrascale Cloud Services innovation cloud is a superior choice for companies needing dedicated, long-term cloud-based servers. You'll be charged one flat rate per month-no ingress or egress fees, no overage charges, no surprises. Plus, we provide a level of support that goes beyond other providers.   -----"
        }
    },
    {
        "chunk_id": "f2f69180-c8d1-4c6d-ac4e-f17eb02f7ef7",
        "text": "## **Cirrascale Cloud Services is a premier cloud services provider of deep learning ** **infrastructure solutions **  We truly embody the spirit of innovation as well as the desire and willingness to share our knowledge and experience with others.  **Our Story** It's surprising how often we are asked about our experience and what makes us qualified to suggest hardware and cloud-based solutions. Cirrascale was a premier developer of blade and rackmount solutions enabling large scale compute",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 2,
            "chunk_id": "f2f69180-c8d1-4c6d-ac4e-f17eb02f7ef7",
            "embedding_model": "text-embedding-3-large",
            "text": "## **Cirrascale Cloud Services is a premier cloud services provider of deep learning ** **infrastructure solutions **  We truly embody the spirit of innovation as well as the desire and willingness to share our knowledge and experience with others.  **Our Story** It's surprising how often we are asked about our experience and what makes us qualified to suggest hardware and cloud-based solutions. Cirrascale was a premier developer of blade and rackmount solutions enabling large scale compute"
        }
    },
    {
        "chunk_id": "aa906b0c-a6a1-4127-aba2-f1347e1a7223",
        "text": "rackmount solutions enabling large scale compute infrastructure. Cirrascale leveraged its patented Vertical Cooling Technology and proprietary PCIe switch riser technology to provide the industry's densest rackmount and blade-based peered multi-GPU platforms.  In late 2015, Cirrascale Corporation decided to launch a cloud service to help those customers interested in a more robust and versatile cloud offering for multi-GPU solutions. The service was well received, and in early 2017, Cirrascale",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 2,
            "chunk_id": "aa906b0c-a6a1-4127-aba2-f1347e1a7223",
            "embedding_model": "text-embedding-3-large",
            "text": "rackmount solutions enabling large scale compute infrastructure. Cirrascale leveraged its patented Vertical Cooling Technology and proprietary PCIe switch riser technology to provide the industry's densest rackmount and blade-based peered multi-GPU platforms.  In late 2015, Cirrascale Corporation decided to launch a cloud service to help those customers interested in a more robust and versatile cloud offering for multi-GPU solutions. The service was well received, and in early 2017, Cirrascale"
        }
    },
    {
        "chunk_id": "ac69ddb7-dc93-4c5a-b47a-30527cd59973",
        "text": "was well received, and in early 2017, Cirrascale Corporation sold its hardware business and spun off the cloud services division as a new separate company, Cirrascale Cloud Services.  Cirrascale Cloud Services continues to expand its growing business and provide Infrastructure-as-a-Service cloud offerings and other professional services to customers like  you.  **What Guides Us**  Our company is guided by a steadfast commitment to integrity, ensuring that every decision and action aligns with",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 2,
            "chunk_id": "ac69ddb7-dc93-4c5a-b47a-30527cd59973",
            "embedding_model": "text-embedding-3-large",
            "text": "was well received, and in early 2017, Cirrascale Corporation sold its hardware business and spun off the cloud services division as a new separate company, Cirrascale Cloud Services.  Cirrascale Cloud Services continues to expand its growing business and provide Infrastructure-as-a-Service cloud offerings and other professional services to customers like  you.  **What Guides Us**  Our company is guided by a steadfast commitment to integrity, ensuring that every decision and action aligns with"
        }
    },
    {
        "chunk_id": "7df58094-ba09-46f4-8d97-7e4a4d0b2bcf",
        "text": "that every decision and action aligns with our core values and ethical standards. We embrace agility, adapting swiftly to changing environments and customer needs, which allows us to deliver innovative solutions efficiently. Our focus on customer centricity and expertise enables us to provide unparalleled service, always striving to exceed expectations and drive success for our clients.  **Integrity** We lead with honesty and integrity in everything we do. ​ ​ **Agile** We adapt quickly to meet",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 2,
            "chunk_id": "7df58094-ba09-46f4-8d97-7e4a4d0b2bcf",
            "embedding_model": "text-embedding-3-large",
            "text": "that every decision and action aligns with our core values and ethical standards. We embrace agility, adapting swiftly to changing environments and customer needs, which allows us to deliver innovative solutions efficiently. Our focus on customer centricity and expertise enables us to provide unparalleled service, always striving to exceed expectations and drive success for our clients.  **Integrity** We lead with honesty and integrity in everything we do. ​ ​ **Agile** We adapt quickly to meet"
        }
    },
    {
        "chunk_id": "1ed0b1a2-b016-4507-9a48-9f383d3553de",
        "text": "we do. ​ ​ **Agile** We adapt quickly to meet evolving challenges. ​ ​  **Customer-Centric**  Cirracscale has a customer-centric ideology to business.  **Expertise** We deliver specialized, innovative solutions.  **Our AI Ecosystem Software Partners**   -----",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 2,
            "chunk_id": "1ed0b1a2-b016-4507-9a48-9f383d3553de",
            "embedding_model": "text-embedding-3-large",
            "text": "we do. ​ ​ **Agile** We adapt quickly to meet evolving challenges. ​ ​  **Customer-Centric**  Cirracscale has a customer-centric ideology to business.  **Expertise** We deliver specialized, innovative solutions.  **Our AI Ecosystem Software Partners**   -----"
        }
    },
    {
        "chunk_id": "97e5f500-0a2f-481b-b19a-6b5f84aad3e3",
        "text": "As one of the leading multi-accelerator cloud providers, we have a lot of partners that are working to further the advancements of deep learning. We wanted to build a community where we could help our customers connect with our partners to save time, money, and resources.  The partners included in our AI Ecosystem have tested their products on our platform and have worked special arrangements with us to provide their solutions to you through our cloud service. They've all agreed to offer their",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 3,
            "chunk_id": "97e5f500-0a2f-481b-b19a-6b5f84aad3e3",
            "embedding_model": "text-embedding-3-large",
            "text": "As one of the leading multi-accelerator cloud providers, we have a lot of partners that are working to further the advancements of deep learning. We wanted to build a community where we could help our customers connect with our partners to save time, money, and resources.  The partners included in our AI Ecosystem have tested their products on our platform and have worked special arrangements with us to provide their solutions to you through our cloud service. They've all agreed to offer their"
        }
    },
    {
        "chunk_id": "b07682fc-13bb-4bdf-b89d-25359c787ac2",
        "text": "cloud service. They've all agreed to offer their services as a flat-rate included with our service, or as a stand-alone product, so you can continue to trust that you won't ever get a variable bill from us.  **RedHat** ​ Cirrascale Cloud Services is proud to partner with Red Hat as a Red Hat Certified Cloud Service Provider. Red Hat® Enterprise Linux® is the world’s leading enterprise Linux platform. It’s an open source operating system (OS) and the foundation from which you can scale existing",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 3,
            "chunk_id": "b07682fc-13bb-4bdf-b89d-25359c787ac2",
            "embedding_model": "text-embedding-3-large",
            "text": "cloud service. They've all agreed to offer their services as a flat-rate included with our service, or as a stand-alone product, so you can continue to trust that you won't ever get a variable bill from us.  **RedHat** ​ Cirrascale Cloud Services is proud to partner with Red Hat as a Red Hat Certified Cloud Service Provider. Red Hat® Enterprise Linux® is the world’s leading enterprise Linux platform. It’s an open source operating system (OS) and the foundation from which you can scale existing"
        }
    },
    {
        "chunk_id": "e2ab2ca6-a9f8-4789-9134-8a98168ec518",
        "text": "the foundation from which you can scale existing apps — and roll out emerging technologies — across bare-metal, virtual, container, as well as other cloud environments supported on the Cirrascale Cloud Platform.  **WekalO** ​ The absolute fastest storage offering to remove bottlenecks faced by customers who use inference training datasets consisting of millions of files to improve outcomes and increase accuracy of deep learning models. WekaIO’s Matrix software is a fully parallel and",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 3,
            "chunk_id": "e2ab2ca6-a9f8-4789-9134-8a98168ec518",
            "embedding_model": "text-embedding-3-large",
            "text": "the foundation from which you can scale existing apps — and roll out emerging technologies — across bare-metal, virtual, container, as well as other cloud environments supported on the Cirrascale Cloud Platform.  **WekalO** ​ The absolute fastest storage offering to remove bottlenecks faced by customers who use inference training datasets consisting of millions of files to improve outcomes and increase accuracy of deep learning models. WekaIO’s Matrix software is a fully parallel and"
        }
    },
    {
        "chunk_id": "bfe4c379-7191-4921-bab1-3b20cdaab792",
        "text": "WekaIO’s Matrix software is a fully parallel and distributed file system that has been designed from scratch to leverage Flash technology. Both data and metadata are distributed across the entire storage infrastructure to ensure massively parallel  access to NVMe drives.  **IBM Power AI**  PowerAI Vision makes computer vision with deep learning more accessible to business users. PowerAI Vision includes an intuitive toolset that empowers subject matter experts to label, train, and deploy deep",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 3,
            "chunk_id": "bfe4c379-7191-4921-bab1-3b20cdaab792",
            "embedding_model": "text-embedding-3-large",
            "text": "WekaIO’s Matrix software is a fully parallel and distributed file system that has been designed from scratch to leverage Flash technology. Both data and metadata are distributed across the entire storage infrastructure to ensure massively parallel  access to NVMe drives.  **IBM Power AI**  PowerAI Vision makes computer vision with deep learning more accessible to business users. PowerAI Vision includes an intuitive toolset that empowers subject matter experts to label, train, and deploy deep"
        }
    },
    {
        "chunk_id": "6b328d99-fe81-42cc-972d-4f936ea26df9",
        "text": "matter experts to label, train, and deploy deep learning vision models, without coding or deep learning expertise. It includes the most popular deep learning frameworks and their dependencies, and it is built for easy and rapid deployment and increased team productivity. By combining PowerAI Vision software with accelerated IBM® Power Systems™, enterprises can rapidly deploy a fully optimized and supported platform with blazing performance.  **KubeFlow** ​ The Kubeflow project is dedicated to",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 3,
            "chunk_id": "6b328d99-fe81-42cc-972d-4f936ea26df9",
            "embedding_model": "text-embedding-3-large",
            "text": "matter experts to label, train, and deploy deep learning vision models, without coding or deep learning expertise. It includes the most popular deep learning frameworks and their dependencies, and it is built for easy and rapid deployment and increased team productivity. By combining PowerAI Vision software with accelerated IBM® Power Systems™, enterprises can rapidly deploy a fully optimized and supported platform with blazing performance.  **KubeFlow** ​ The Kubeflow project is dedicated to"
        }
    },
    {
        "chunk_id": "6ed539d0-a711-4a4a-8db4-892eb948c950",
        "text": "​ The Kubeflow project is dedicated to making deployments of machine learning (ML) workflows on Kubernetes simple, portable and scalable. Its goal is to make scaling machine learning (ML) models and deploying them to production as simple as possible, by letting Kubernetes do what it’s great at: (1) Easy, repeatable, portable deployments on a diverse infrastructure, (2) Deploying and managing loosely-coupled microservices, (3) Scaling based on demand. Anywhere you are running Kubernetes, you",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 3,
            "chunk_id": "6ed539d0-a711-4a4a-8db4-892eb948c950",
            "embedding_model": "text-embedding-3-large",
            "text": "​ The Kubeflow project is dedicated to making deployments of machine learning (ML) workflows on Kubernetes simple, portable and scalable. Its goal is to make scaling machine learning (ML) models and deploying them to production as simple as possible, by letting Kubernetes do what it’s great at: (1) Easy, repeatable, portable deployments on a diverse infrastructure, (2) Deploying and managing loosely-coupled microservices, (3) Scaling based on demand. Anywhere you are running Kubernetes, you"
        }
    },
    {
        "chunk_id": "05a543dc-8e34-4ad0-89d3-665dc44d9dc2",
        "text": "demand. Anywhere you are running Kubernetes, you should be able to run Kubeflow.  **One Convergence** ​ With DKube from One Convergence, the data scientists do not need extensive IT expertise to find, download, and maintain ML frameworks, CUDA libraries, RDMA tools and various of other   -----",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 3,
            "chunk_id": "05a543dc-8e34-4ad0-89d3-665dc44d9dc2",
            "embedding_model": "text-embedding-3-large",
            "text": "demand. Anywhere you are running Kubernetes, you should be able to run Kubeflow.  **One Convergence** ​ With DKube from One Convergence, the data scientists do not need extensive IT expertise to find, download, and maintain ML frameworks, CUDA libraries, RDMA tools and various of other   -----"
        }
    },
    {
        "chunk_id": "646ceed7-db59-4650-87d8-3e3e1e3f1ffe",
        "text": "tools and libraries. Dkube installs on the Cirrascale Cloud Services platform in less than hour and can onboard a customer's data scientists quickly allowing them to conduct their Tensorflow or PyTorch experiments with ease.  **H2O AI**  H2O is a fully open source, distributed in-memory ML platform with linear scalability. H2O supports the most widely used statistical and machine learning algorithms including gradient boosted machines, generalized linear models, deep learning and more. It has an",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 4,
            "chunk_id": "646ceed7-db59-4650-87d8-3e3e1e3f1ffe",
            "embedding_model": "text-embedding-3-large",
            "text": "tools and libraries. Dkube installs on the Cirrascale Cloud Services platform in less than hour and can onboard a customer's data scientists quickly allowing them to conduct their Tensorflow or PyTorch experiments with ease.  **H2O AI**  H2O is a fully open source, distributed in-memory ML platform with linear scalability. H2O supports the most widely used statistical and machine learning algorithms including gradient boosted machines, generalized linear models, deep learning and more. It has an"
        }
    },
    {
        "chunk_id": "26e99396-2304-4ede-9ef0-44d2ef2cdd50",
        "text": "linear models, deep learning and more. It has an industry leading AutoML functionality that automatically runs through all the algorithms and their hyperparameters to produce a leaderboard of the best models.   -----",
        "metadata": {
            "parent_document_id": "About Cirrascale.pdf",
            "parent_content_hash": "9f02fbebdd8925f59bd1f6ac9562eac5282a7f54b6a2d0691932748281e5720c",
            "source_type": "pdf_chunk",
            "original_source_path": "data/cirrascale/text_data/About Cirrascale.pdf",
            "page_number": 4,
            "chunk_id": "26e99396-2304-4ede-9ef0-44d2ef2cdd50",
            "embedding_model": "text-embedding-3-large",
            "text": "linear models, deep learning and more. It has an industry leading AutoML functionality that automatically runs through all the algorithms and their hyperparameters to produce a leaderboard of the best models.   -----"
        }
    }
]